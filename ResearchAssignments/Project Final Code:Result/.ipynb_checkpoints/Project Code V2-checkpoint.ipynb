{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddfa7ea7-e4ce-49b6-82e9-a06316d0935d",
   "metadata": {},
   "source": [
    "# Notebook Overview & Goals\n",
    "\n",
    "This notebook serves as a comprehensive, end-to-end pipeline for analyzing the interaction between M31 and M33 in a cosmological context. Specifically, it will:\n",
    "\n",
    "- **Read** the snapshot data for both M31 and M33 at various times.\n",
    "- **Compute** key parameters such as the Jacobi (tidal) radius and bound mass of M33 to understand its mass-loss history.\n",
    "- **Generate** surface density profiles of M33’s stellar disk and fit Sersic or exponential profiles over time.\n",
    "- **Analyze** morphological features of M33 (e.g., spiral arms, warping, scale height) by rotating its coordinate system into face-on and edge-on views.\n",
    "- **Compare** these results to theoretical models for tidal interactions and disk evolution, with an eye toward how mass loss correlates with morphological changes.\n",
    "\n",
    "Ultimately, the outputs from this notebook (plots, tables, best-fit parameters, etc.) will form the quantitative backbone of a 5–6 page final research paper, giving us both the raw data and visual diagnostics to draw robust scientific conclusions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab45ffe8-16e1-48c4-b10a-767f17c8a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.1: Imports & Logging Configuration\n",
    "\n",
    "# -------------------------\n",
    "# Standard Python imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Optional: Astropy or SciPy if needed\n",
    "import astropy.units as u\n",
    "from astropy import constants as const\n",
    "from scipy.optimize import curve_fit\n",
    "# etc. for any other modules you anticipate using\n",
    "\n",
    "# -------------------------\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,             # Choose DEBUG, INFO, WARNING, ERROR as needed\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout),\n",
    "        # Could add a file handler if you want logs saved to a file:\n",
    "        # logging.FileHandler('notebook_log.txt', mode='w')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Example of logging usage\n",
    "logging.info(\"Notebook started. Libraries imported successfully.\")\n",
    "\n",
    "# -------------------------\n",
    "# Global constants (example)\n",
    "G_kpcGyrMsun = 4.499e-6  # Gravitational constant in kpc^3 / Gyr^2 / Msun\n",
    "M31_halo_mass = 1.5e12   # Msun, total halo mass for M31\n",
    "M31_scale_radius = 60.0  # kpc, Hernquist scale radius for M31\n",
    "\n",
    "# We’ll expand or modify these as needed in subsequent cells.\n",
    "print(\"Cell 1.1 completed: Libraries and logging configured.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef203f5-b3c7-4b83-aaf3-3e50a333614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.2: User-Configurable Parameters & Filenames\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Directories for snapshot files\n",
    "# Provide the paths to where M31_000.txt, M33_000.txt, etc. reside.\n",
    "M31_DIRECTORY = \"M31/\"  # e.g., \"data/M31/\" or an absolute path\n",
    "M33_DIRECTORY = \"M33/\"  # e.g., \"data/M33/\" or an absolute path\n",
    "\n",
    "# Snapshots might also have consistent naming, like M31_000.txt, M31_001.txt, etc.\n",
    "# If there's a different naming scheme, specify here or in parse functions.\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Tidal / mass-loss configuration\n",
    "ROUTER_LIMIT = 30.0   # Max radius for bound mass check (kpc)\n",
    "                     # We'll take min(R_jacobi, ROUTER_LIMIT) when summing bound mass.\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Surface density profile configuration\n",
    "NBINS_PROFILES = 30   # Number of radial bins (annuli) for the surface density computation\n",
    "RMAX_PROFILES  = 30.0 # kpc out to which we compute the radial profile\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Additional config variables \n",
    "# (You can add or remove as needed throughout the analysis)\n",
    "M31_HALO_MASS   = 1.5e12   # Msun, total halo mass for M31 if using Hernquist\n",
    "M31_SCALE_RADIUS = 60.0    # kpc, scale radius for M31's Hernquist profile\n",
    "\n",
    "# Data logging or output options\n",
    "SAVE_INTERMEDIATE_RESULTS = True  # If True, we’ll save .npy/.txt files at various steps\n",
    "PLOTS_DIRECTORY           = \"plots/\"   # Where to store generated plots\n",
    "RESULTS_DIRECTORY         = \"results/\" # Where to store numeric outputs\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Print for user confirmation\n",
    "print(\"Cell 1.2 completed: User-configurable parameters and filenames set.\")\n",
    "print(f\"M31 files assumed to be in: {M31_DIRECTORY}\")\n",
    "print(f\"M33 files assumed to be in: {M33_DIRECTORY}\")\n",
    "print(f\"Router limit for bound mass: {ROUTER_LIMIT} kpc\")\n",
    "print(f\"Surface density profile: {NBINS_PROFILES} radial bins, rmax={RMAX_PROFILES} kpc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d84a1-b2b8-497e-ac53-932527da72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 2.1 — \"File Parsing Functions\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import logging\n",
    "import re  # if we need to parse snapshot indices from filenames\n",
    "\n",
    "def parse_galaxy_file(filename):\n",
    "    \"\"\"\n",
    "    Reads a galaxy snapshot file (e.g., M31_000.txt or M33_010.txt)\n",
    "    and returns:\n",
    "        time_val        : float\n",
    "            Time in Gyr from the file header (line with 'Time')\n",
    "        total_particles : int\n",
    "            Number of particles from the file header (line with 'Total')\n",
    "        data_tuple      : tuple of np.ndarrays\n",
    "            (ptype, pmass, x, y, z, vx, vy, vz)\n",
    "\n",
    "    Each data line in the file is assumed to have the columns:\n",
    "       #type, mass(1e10 Msun), x(kpc), y(kpc), z(kpc),\n",
    "       vx(km/s), vy(km/s), vz(km/s)\n",
    "\n",
    "    Column details:\n",
    "    1) type : float or int indicating particle type (e.g., 1.0 for dark matter, 2.0 for disk, etc.)\n",
    "    2) mass : float, in units of 1e10 solar masses\n",
    "    3) x, y, z : floats, positions in kpc\n",
    "    4) vx, vy, vz : floats, velocities in km/s\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path to the snapshot file to read.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    time_val : float\n",
    "        Time (Gyr) of the snapshot from file header.\n",
    "    total_particles : int\n",
    "        Number of particles in the snapshot (from header).\n",
    "    data_tuple : (ptype, pmass, x, y, z, vx, vy, vz)\n",
    "        Each element is a NumPy array of length total_particles.\n",
    "    \"\"\"\n",
    "    time_val = None\n",
    "    total_particles = None\n",
    "\n",
    "    # Lists to store data columns\n",
    "    ptype_list = []\n",
    "    mass_list  = []\n",
    "    x_list     = []\n",
    "    y_list     = []\n",
    "    z_list     = []\n",
    "    vx_list    = []\n",
    "    vy_list    = []\n",
    "    vz_list    = []\n",
    "\n",
    "    # Read the file\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    data_start_idx = None\n",
    "\n",
    "    # Parse header lines\n",
    "    for i, line in enumerate(lines):\n",
    "        line_stripped = line.strip()\n",
    "        # e.g. \"Time      0.00000\"\n",
    "        if line_stripped.startswith(\"Time\"):\n",
    "            parts = line_stripped.split()\n",
    "            time_val = float(parts[1])\n",
    "        elif line_stripped.startswith(\"Total\"):\n",
    "            parts = line_stripped.split()\n",
    "            total_particles = int(parts[1])\n",
    "        elif line_stripped.startswith(\"#type\"):\n",
    "            data_start_idx = i + 1\n",
    "            break\n",
    "\n",
    "    if data_start_idx is None:\n",
    "        logging.warning(f\"parse_galaxy_file: No data header ('#type') found in {filename}\")\n",
    "        return None, None, (None,)*8\n",
    "\n",
    "    # Parse data lines\n",
    "    for line in lines[data_start_idx:]:\n",
    "        line_stripped = line.strip()\n",
    "        if not line_stripped:\n",
    "            continue\n",
    "        parts = line_stripped.split()\n",
    "        if len(parts) < 8:\n",
    "            # Possibly an empty or invalid line, skip\n",
    "            continue\n",
    "\n",
    "        # Extract columns\n",
    "        ptype = float(parts[0])  # e.g. 1.0, 2.0, 3.0\n",
    "        pmass = float(parts[1])\n",
    "        px    = float(parts[2])\n",
    "        py    = float(parts[3])\n",
    "        pz    = float(parts[4])\n",
    "        pvx   = float(parts[5])\n",
    "        pvy   = float(parts[6])\n",
    "        pvz   = float(parts[7])\n",
    "\n",
    "        ptype_list.append(ptype)\n",
    "        mass_list.append(pmass)\n",
    "        x_list.append(px)\n",
    "        y_list.append(py)\n",
    "        z_list.append(pz)\n",
    "        vx_list.append(pvx)\n",
    "        vy_list.append(pvy)\n",
    "        vz_list.append(pvz)\n",
    "\n",
    "    import numpy as np\n",
    "    ptype_array = np.array(ptype_list)\n",
    "    mass_array  = np.array(mass_list)\n",
    "    x_array     = np.array(x_list)\n",
    "    y_array     = np.array(y_list)\n",
    "    z_array     = np.array(z_list)\n",
    "    vx_array    = np.array(vx_list)\n",
    "    vy_array    = np.array(vy_list)\n",
    "    vz_array    = np.array(vz_list)\n",
    "\n",
    "    if total_particles is not None and len(ptype_array) != total_particles:\n",
    "        logging.warning(f\"parse_galaxy_file: Mismatch in count. Header says {total_particles}, \"\n",
    "                        f\"but we read {len(ptype_array)} lines of data in {filename}\")\n",
    "\n",
    "    logging.info(f\"Parsed file: {filename} | time={time_val} Gyr | total_particles={len(ptype_array)}\")\n",
    "    data_tuple = (ptype_array, mass_array, x_array, y_array, z_array, vx_array, vy_array, vz_array)\n",
    "    return time_val, len(ptype_array), data_tuple\n",
    "\n",
    "\n",
    "def get_snapshot_index(filename):\n",
    "    \"\"\"\n",
    "    Extract snapshot index from a filename that might look like 'M31_003.txt'\n",
    "    If we find an underscore followed by digits, we return that integer.\n",
    "    If none found, return None.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> get_snapshot_index(\"M31_003.txt\")\n",
    "    3\n",
    "    >>> get_snapshot_index(\"M33_050.txt\")\n",
    "    50\n",
    "    \"\"\"\n",
    "    match = re.search(r'_([0-9]+)\\.txt', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "print(\"Cell 2.1 completed: parse_galaxy_file() and get_snapshot_index() defined in memory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12205833-10e5-4110-8bf4-51346f2565ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 2.2 — \"Center of Mass & Other Shared Math Routines\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "def center_of_mass(x, y, z, mass):\n",
    "    \"\"\"\n",
    "    Compute the center-of-mass for a set of particles with positions (x, y, z)\n",
    "    and masses 'mass'.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y, z : np.array\n",
    "        Positions in kpc (or any consistent unit).\n",
    "    mass : np.array\n",
    "        Mass of each particle (in e.g. 1e10 Msun units or Msun, but must be consistent).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xcom, ycom, zcom : float\n",
    "        The coordinates of the center of mass in the same units as x, y, z.\n",
    "    \"\"\"\n",
    "    M_total = np.sum(mass)\n",
    "    if M_total == 0:\n",
    "        logging.warning(\"center_of_mass: Total mass is zero. Returning (0,0,0).\")\n",
    "        return 0.0, 0.0, 0.0\n",
    "\n",
    "    xcom = np.sum(x * mass) / M_total\n",
    "    ycom = np.sum(y * mass) / M_total\n",
    "    zcom = np.sum(z * mass) / M_total\n",
    "\n",
    "    return xcom, ycom, zcom\n",
    "\n",
    "\n",
    "def hernquist_enclosed_mass(r, M_halo=1.5e12, a=60.0):\n",
    "    \"\"\"\n",
    "    Computes the enclosed mass for a Hernquist profile:\n",
    "       M(r) = M_halo * [r^2 / (r + a)^2]\n",
    "\n",
    "    Typically used to approximate M31's halo mass distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r : float or np.array\n",
    "        Radius (kpc).\n",
    "    M_halo : float\n",
    "        Total halo mass in Msun (default 1.5e12 Msun).\n",
    "    a : float\n",
    "        Scale radius in kpc (default 60 kpc).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    M_enc : float or np.array\n",
    "        Enclosed mass (Msun) at radius r.\n",
    "    \"\"\"\n",
    "    # We assume r >= 0. If r is an array, this function\n",
    "    # will handle it element-wise.\n",
    "    r = np.array(r, ndmin=1)  # ensure array for safe math\n",
    "    M_enc = M_halo * (r**2 / (r + a)**2)\n",
    "    # If r was scalar, we might want to return a scalar\n",
    "    if M_enc.size == 1:\n",
    "        return M_enc[0]\n",
    "    return M_enc\n",
    "\n",
    "\n",
    "def distance_3d(x1, y1, z1, x2, y2, z2):\n",
    "    \"\"\"\n",
    "    Simple helper function to compute 3D distance between two points (x1,y1,z1) and (x2,y2,z2).\n",
    "    Returns the distance in the same unit as x,y,z input.\n",
    "    \"\"\"\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    dz = z2 - z1\n",
    "    return np.sqrt(dx*dx + dy*dy + dz*dz)\n",
    "\n",
    "\n",
    "def vector_magnitude(x, y, z):\n",
    "    \"\"\"\n",
    "    Returns sqrt(x^2 + y^2 + z^2), useful for computing radii, velocity magnitude, etc.\n",
    "    If x,y,z are np.arrays, does element-wise operation.\n",
    "    \"\"\"\n",
    "    return np.sqrt(x*x + y*y + z*z)\n",
    "\n",
    "\n",
    "print(\"Cell 2.2 completed: center_of_mass(), hernquist_enclosed_mass(), distance_3d(), vector_magnitude() defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f37356c-807e-4f53-b209-b3a9ec9bc40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 2.3 — \"Diagnostic Test: Single Snapshot Parsing & Printout\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "\n",
    "# We'll use the user-configurable directories from Cell 1.2:\n",
    "#   M31_DIRECTORY, M33_DIRECTORY\n",
    "# We'll read e.g. M31_000.txt, M33_000.txt to do a quick test.\n",
    "\n",
    "# Let's define a small function that tries the first snapshot for M31 and M33.\n",
    "\n",
    "def diagnostic_test_single_snapshot(snapshot_index=0):\n",
    "    \"\"\"\n",
    "    Parses a single M31 and M33 snapshot (e.g. M31_000.txt, M33_000.txt),\n",
    "    prints out some basic info: time, number of particles, center-of-mass, etc.\n",
    "    \"\"\"\n",
    "    from IPython.display import display\n",
    "    import logging\n",
    "\n",
    "    # Construct filenames\n",
    "    file_m31 = f\"{M31_DIRECTORY}M31_{snapshot_index:03d}.txt\"\n",
    "    file_m33 = f\"{M33_DIRECTORY}M33_{snapshot_index:03d}.txt\"\n",
    "\n",
    "    if not (os.path.exists(file_m31) and os.path.exists(file_m33)):\n",
    "        logging.warning(f\"Cannot find M31 or M33 snapshot for index={snapshot_index}\")\n",
    "        return\n",
    "\n",
    "    # Parse M31\n",
    "    t_m31, count_m31, (ptype_m31, mass_m31, x_m31, y_m31, z_m31, vx_m31, vy_m31, vz_m31) = parse_galaxy_file(file_m31)\n",
    "    # Parse M33\n",
    "    t_m33, count_m33, (ptype_m33, mass_m33, x_m33, y_m33, z_m33, vx_m33, vy_m33, vz_m33) = parse_galaxy_file(file_m33)\n",
    "\n",
    "    # Print times\n",
    "    print(f\"\\n=== Diagnostic Test for Snap Index {snapshot_index:03d} ===\")\n",
    "    print(f\" M31: time={t_m31} Gyr, total_particles={count_m31}\")\n",
    "    print(f\" M33: time={t_m33} Gyr, total_particles={count_m33}\")\n",
    "\n",
    "    # Compute COM for M31\n",
    "    from math import isnan\n",
    "    xcom_m31, ycom_m31, zcom_m31 = center_of_mass(x_m31, y_m31, z_m31, mass_m31)\n",
    "    xcom_m33, ycom_m33, zcom_m33 = center_of_mass(x_m33, y_m33, z_m33, mass_m33)\n",
    "\n",
    "    print(f\" M31 COM: ({xcom_m31:.3f}, {ycom_m31:.3f}, {zcom_m31:.3f}) kpc\")\n",
    "    print(f\" M33 COM: ({xcom_m33:.3f}, {ycom_m33:.3f}, {zcom_m33:.3f}) kpc\")\n",
    "\n",
    "    # Quick total mass check (in 1e10 Msun units for the file).\n",
    "    # Typically, we multiply by 1e10 to get Msun.\n",
    "    m31_total_mass = mass_m31.sum() * 1e10\n",
    "    m33_total_mass = mass_m33.sum() * 1e10\n",
    "    print(f\" M31 total mass (raw sum): {m31_total_mass:.2e} Msun\")\n",
    "    print(f\" M33 total mass (raw sum): {m33_total_mass:.2e} Msun\")\n",
    "\n",
    "    # Confirm times should match or be very close\n",
    "    if abs(t_m31 - t_m33) > 1e-3:\n",
    "        logging.warning(\"Times for M31 vs. M33 in same snap index differ significantly!\")\n",
    "\n",
    "# Now let's call this test function for the default snapshot_index=0\n",
    "diagnostic_test_single_snapshot(snapshot_index=0)\n",
    "\n",
    "print(\"\\nCell 2.3 completed: Single snapshot parsing & printout diagnostic ran.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed5b17c-ea02-484c-bcf5-5567e7ecbaef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 3.1.1 — \"Compute & Store Jacobi Radius for All Snapshots\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "def compute_jacobi_all_snaps(save_results=SAVE_INTERMEDIATE_RESULTS):\n",
    "    \"\"\"\n",
    "    Loop over all M31/*.txt and M33/*.txt snapshot files, compute the Jacobi radius (R_j) for M33.\n",
    "\n",
    "    Steps for each snapshot index:\n",
    "    1) Identify matching snapshot files M31_xxx.txt, M33_xxx.txt\n",
    "    2) Parse data and compute center-of-mass for M31 & M33\n",
    "    3) Compute relative distance R = distance(M31_COM, M33_COM)\n",
    "    4) Compute enclosed host mass: Mhost_enc = hernquist_enclosed_mass(R)\n",
    "    5) Compute total M33 mass: M33_sat_mass = sum of M33 masses * 1e10 Msun\n",
    "    6) Jacobi radius: R_j = R * (M33_sat_mass / (2 * Mhost_enc))^(1/3)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    save_results : bool\n",
    "        If True, saves the results as a .npy file in RESULTS_DIRECTORY\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    times_jacobi : np.ndarray\n",
    "        Array of times (Gyr) for each snapshot\n",
    "    rjacobi_arr  : np.ndarray\n",
    "        Jacobi radii (kpc) for each snapshot\n",
    "    \"\"\"\n",
    "    # We rely on the M31_DIRECTORY, M33_DIRECTORY from Cell 1.2\n",
    "    # Also on parse_galaxy_file, center_of_mass, hernquist_enclosed_mass from earlier cells.\n",
    "    \n",
    "    m31_pattern = os.path.join(M31_DIRECTORY, \"M31_*.txt\")\n",
    "    m33_pattern = os.path.join(M33_DIRECTORY, \"M33_*.txt\")\n",
    "\n",
    "    m31_files = sorted(glob.glob(m31_pattern))\n",
    "    m33_files = sorted(glob.glob(m33_pattern))\n",
    "\n",
    "    # Helper function to get snapshot index from file name\n",
    "    def get_snapidx(fname):\n",
    "        return get_snapshot_index(fname)  # from Cell 2.1\n",
    "\n",
    "    # Build dict: index -> filename for M31, M33\n",
    "    m31_dict = {}\n",
    "    for f in m31_files:\n",
    "        idx = get_snapidx(f)\n",
    "        if idx is not None:\n",
    "            m31_dict[idx] = f\n",
    "\n",
    "    m33_dict = {}\n",
    "    for f in m33_files:\n",
    "        idx = get_snapidx(f)\n",
    "        if idx is not None:\n",
    "            m33_dict[idx] = f\n",
    "\n",
    "    # Find common snapshot indices\n",
    "    common_indices = sorted(set(m31_dict.keys()) & set(m33_dict.keys()))\n",
    "    if not common_indices:\n",
    "        logging.warning(\"No matching snapshot indices found between M31 and M33 directories!\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    times_list = []\n",
    "    rj_list    = []\n",
    "\n",
    "    for snap_idx in common_indices:\n",
    "        # Parse M31\n",
    "        file_m31 = m31_dict[snap_idx]\n",
    "        t_m31, count_m31, data_m31 = parse_galaxy_file(file_m31)\n",
    "        (ptype_m31, mass_m31, x_m31, y_m31, z_m31, vx_m31, vy_m31, vz_m31) = data_m31\n",
    "\n",
    "        # Parse M33\n",
    "        file_m33 = m33_dict[snap_idx]\n",
    "        t_m33, count_m33, data_m33 = parse_galaxy_file(file_m33)\n",
    "        (ptype_m33, mass_m33, x_m33, y_m33, z_m33, vx_m33, vy_m33, vz_m33) = data_m33\n",
    "\n",
    "        # We'll assume times are essentially the same for M31 & M33 in the same snapshot\n",
    "        t_val = 0.5*(t_m31 + t_m33)\n",
    "\n",
    "        # Center of mass for M31 & M33\n",
    "        xcom_m31, ycom_m31, zcom_m31 = center_of_mass(x_m31, y_m31, z_m31, mass_m31)\n",
    "        xcom_m33, ycom_m33, zcom_m33 = center_of_mass(x_m33, y_m33, z_m33, mass_m33)\n",
    "\n",
    "        # Relative distance R\n",
    "        dx = xcom_m33 - xcom_m31\n",
    "        dy = ycom_m33 - ycom_m31\n",
    "        dz = zcom_m33 - zcom_m31\n",
    "        R  = np.sqrt(dx*dx + dy*dy + dz*dz)\n",
    "\n",
    "        # Enclosed host mass from M31\n",
    "        Mhost_enc = hernquist_enclosed_mass(R, M_halo=M31_HALO_MASS, a=M31_SCALE_RADIUS)\n",
    "\n",
    "        # M33 total mass (in Msun)\n",
    "        # file mass is in 1e10 Msun\n",
    "        M33_sat_mass = np.sum(mass_m33) * 1e10\n",
    "\n",
    "        # Jacobi radius\n",
    "        # R_j = R * (M33_sat_mass / (2 * Mhost_enc))^(1/3)\n",
    "        if Mhost_enc <= 0:\n",
    "            logging.warning(f\"compute_jacobi_all_snaps: Mhost_enc <= 0 for snap {snap_idx}, skipping.\")\n",
    "            continue\n",
    "        R_j = R * ((M33_sat_mass / (2.0 * Mhost_enc)) ** (1.0/3.0))\n",
    "\n",
    "        # Logging checks\n",
    "        if R_j <= 0:\n",
    "            logging.warning(f\"Jacobi radius <= 0 for snap {snap_idx}. Possibly no M33 mass or Mhost_enc invalid.\")\n",
    "        if R_j > 300:\n",
    "            logging.warning(f\"Suspiciously large Jacobi radius (R_j={R_j:.2f} kpc) for snap {snap_idx} at time={t_val:.2f} Gyr.\")\n",
    "\n",
    "        logging.info(f\"Snap {snap_idx:03d} | time={t_val:.3f} Gyr | R={R:.2f} kpc | R_j={R_j:.2f} kpc\")\n",
    "\n",
    "        times_list.append(t_val)\n",
    "        rj_list.append(R_j)\n",
    "\n",
    "    # Convert to arrays\n",
    "    times_jacobi = np.array(times_list)\n",
    "    rjacobi_arr  = np.array(rj_list)\n",
    "\n",
    "    # Sort by time\n",
    "    sort_idx = np.argsort(times_jacobi)\n",
    "    times_jacobi = times_jacobi[sort_idx]\n",
    "    rjacobi_arr  = rjacobi_arr[sort_idx]\n",
    "\n",
    "    if save_results and len(times_jacobi) > 0:\n",
    "        # Make sure the directory exists\n",
    "        os.makedirs(RESULTS_DIRECTORY, exist_ok=True)  # Creates 'results/' if missing\n",
    "        \n",
    "        outfile = os.path.join(RESULTS_DIRECTORY, \"jacobi_radius_vs_time.npy\")\n",
    "        np.save(outfile, np.column_stack((times_jacobi, rjacobi_arr)))\n",
    "        logging.info(f\"Jacobi radius results saved to {outfile}\")\n",
    "\n",
    "    return times_jacobi, rjacobi_arr\n",
    "\n",
    "\n",
    "# Immediately run the function to fill in memory with results\n",
    "times_jacobi, rjacobi_arr = compute_jacobi_all_snaps()\n",
    "print(\"Cell 3.1.1 completed: Jacobi radius computed for all snapshots.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e088742-d4e6-46c6-aef0-4872c431cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 3.1.2 — \"Jacobi Radius vs. Time: Plots & Analysis\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_jacobi_radius(times_jacobi, rjacobi_arr, outfig=\"jacobi_radius_over_time.png\"):\n",
    "    \"\"\"\n",
    "    Takes the array (times_jacobi, rjacobi_arr), creates a line/scatter plot\n",
    "    of R_jacobi vs. time, and optionally fits a smoothing or polynomial for clarity.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    times_jacobi : np.ndarray\n",
    "        times in Gyr\n",
    "    rjacobi_arr : np.ndarray\n",
    "        Jacobi radius in kpc\n",
    "    outfig : str\n",
    "        Filename to save the plot. If None, won't save.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    (Generates a plot)\n",
    "    \"\"\"\n",
    "    if len(times_jacobi) == 0:\n",
    "        print(\"No Jacobi radius data to plot.\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.plot(times_jacobi, rjacobi_arr, '-', label='Jacobi Radius (kpc)')\n",
    "    ax.set_xlabel(\"Time (Gyr)\")\n",
    "    ax.set_ylabel(\"R$_{J}$ (kpc)\")\n",
    "    ax.set_title(\"Jacobi Radius vs. Time\")\n",
    "\n",
    "    # Optionally, a simple polynomial fit for interpretive clarity\n",
    "    # e.g. if you want a 2nd or 3rd order polynomial. \n",
    "    # We'll just do a demonstration of a small fit if data > some threshold.\n",
    "    if len(times_jacobi) >= 5:\n",
    "        poly_order = 2  # e.g. quadratic\n",
    "        coeffs = np.polyfit(times_jacobi, rjacobi_arr, poly_order)\n",
    "        #polyfunc = np.poly1d(coeffs)\n",
    "        t_fit = np.linspace(times_jacobi[0], times_jacobi[-1], 100)\n",
    "        r_fit = polyfunc(t_fit)\n",
    "        ax.plot(t_fit, r_fit, '--', label=f'Poly{poly_order} Fit', alpha=0.6)\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Possibly add text commentary\n",
    "    plt.text(0.05, 0.85, \n",
    "             \"Note: Strong decline => strong tidal interaction\",\n",
    "             transform=ax.transAxes, fontsize=10, alpha=0.7)\n",
    "\n",
    "    if outfig:\n",
    "        plt.tight_layout()\n",
    "        # Ensure 'plots/' directory is created\n",
    "        os.makedirs(PLOTS_DIRECTORY, exist_ok=True)\n",
    "\n",
    "        outfile = os.path.join(PLOTS_DIRECTORY, outfig)\n",
    "        plt.savefig(outfile, dpi=150)\n",
    "        print(f\"Jacobi radius plot saved to {outfile}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Run the plotting function with the results from Cell 3.1.1\n",
    "plot_jacobi_radius(times_jacobi, rjacobi_arr, outfig=\"jacobi_radius_over_time.png\")\n",
    "\n",
    "print(\"Cell 3.1.2 completed: Jacobi radius vs. time plot and analysis generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bce2f6-3e34-45d2-bfcc-92bcddc8dd13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 3.2.1 — \"Compute & Store M33 Bound Mass for All Snapshots\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "def compute_bound_mass_all_snaps(times_jacobi, rjacobi_arr, \n",
    "                                 router_limit=ROUTER_LIMIT,\n",
    "                                 save_results=SAVE_INTERMEDIATE_RESULTS):\n",
    "    \"\"\"\n",
    "    Compute M33's bound mass over time by capping the radius at min(R_jacobi, router_limit).\n",
    "\n",
    "    Steps for each snapshot index:\n",
    "    1) Identify M33_xxx.txt files (matching M31-based indexing if needed).\n",
    "    2) From the previously computed arrays (times_jacobi, rjacobi_arr),\n",
    "       we know which snapshot index corresponds to which Jacobi radius.\n",
    "    3) For each snapshot:\n",
    "       - parse M33\n",
    "       - shift by M33 COM\n",
    "       - define R_cut = min(R_j, router_limit)\n",
    "       - sum masses of particles within R_cut\n",
    "    4) Return arrays of (time, Mbound).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    times_jacobi : np.ndarray\n",
    "        Times (Gyr) sorted by snapshot index\n",
    "    rjacobi_arr : np.ndarray\n",
    "        Jacobi radii (kpc) sorted by snapshot index\n",
    "    router_limit : float\n",
    "        Outer radius limit (kpc) to define bound region if R_j is too large\n",
    "    save_results : bool\n",
    "        If True, saves the results to .npy in RESULTS_DIRECTORY\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    times_bound : np.ndarray\n",
    "        times in Gyr (matching snapshot order from Jacobi array)\n",
    "    Mbound_arr : np.ndarray\n",
    "        bound mass in Msun at each snapshot\n",
    "    \"\"\"\n",
    "\n",
    "    # We'll find all M33 snapshot files\n",
    "    m33_pattern = os.path.join(M33_DIRECTORY, \"M33_*.txt\")\n",
    "    m33_files = sorted(glob.glob(m33_pattern))\n",
    "\n",
    "    # Build a dict of index->filename for M33\n",
    "    m33_dict = {}\n",
    "    for f in m33_files:\n",
    "        snap_idx = get_snapshot_index(f)\n",
    "        if snap_idx is not None:\n",
    "            m33_dict[snap_idx] = f\n",
    "\n",
    "    if len(times_jacobi) == 0 or len(rjacobi_arr) == 0:\n",
    "        logging.warning(\"compute_bound_mass_all_snaps: No Jacobi radius data provided!\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    # We'll store (time, Mbound) in arrays\n",
    "    times_bound = []\n",
    "    Mbound_arr  = []\n",
    "\n",
    "    snap_rj_dict = {}\n",
    "\n",
    "    m33_snap_indices = sorted(m33_dict.keys())\n",
    "    if len(m33_snap_indices) != len(rjacobi_arr):\n",
    "        logging.warning(\"Mismatch in count of M33 snapshots vs. Jacobi array length. We'll match in order only.\")\n",
    "\n",
    "    # We'll match them in ascending order:\n",
    "    # We'll do i-th index for times_jacobi, rjacobi_arr to the i-th snap in m33_snap_indices\n",
    "    # This is naive but typically works if the snapshots line up exactly.\n",
    "    n_common = min(len(m33_snap_indices), len(rjacobi_arr))\n",
    "    for i in range(n_common):\n",
    "        snap_idx = m33_snap_indices[i]\n",
    "        file_m33 = m33_dict[snap_idx]\n",
    "\n",
    "        t_val    = times_jacobi[i]\n",
    "        R_j      = rjacobi_arr[i]\n",
    "\n",
    "        # parse M33\n",
    "        t_m33, count_m33, data_m33 = parse_galaxy_file(file_m33)\n",
    "        (ptype_m33, mass_m33, x_m33, y_m33, z_m33, vx_m33, vy_m33, vz_m33) = data_m33\n",
    "\n",
    "        # shift M33 by its COM\n",
    "        xcom_m33, ycom_m33, zcom_m33 = center_of_mass(x_m33, y_m33, z_m33, mass_m33)\n",
    "        x_shift = x_m33 - xcom_m33\n",
    "        y_shift = y_m33 - ycom_m33\n",
    "        z_shift = z_m33 - zcom_m33\n",
    "        r_m33   = np.sqrt(x_shift**2 + y_shift**2 + z_shift**2)\n",
    "\n",
    "        # define R_cut\n",
    "        R_cut = min(R_j, router_limit)\n",
    "\n",
    "        # sum masses within R_cut\n",
    "        inside = (r_m33 <= R_cut)\n",
    "        M_bound = np.sum(mass_m33[inside]) * 1e10  # Msun\n",
    "        times_bound.append(t_val)\n",
    "        Mbound_arr.append(M_bound)\n",
    "\n",
    "        logging.info(f\"Snap {snap_idx:03d}, time={t_val:.3f} Gyr | R_j={R_j:.2f} kpc, R_cut={R_cut:.2f} kpc, \"\n",
    "                     f\"M33_bound={M_bound:.2e} Msun\")\n",
    "\n",
    "    times_bound = np.array(times_bound)\n",
    "    Mbound_arr  = np.array(Mbound_arr)\n",
    "\n",
    "    # Sort by time\n",
    "    sort_idx = np.argsort(times_bound)\n",
    "    times_bound = times_bound[sort_idx]\n",
    "    Mbound_arr  = Mbound_arr[sort_idx]\n",
    "\n",
    "    # Save if requested\n",
    "    if save_results and len(times_bound) > 0:\n",
    "        os.makedirs(RESULTS_DIRECTORY, exist_ok=True)\n",
    "        outfile = os.path.join(RESULTS_DIRECTORY, \"m33_bound_mass_vs_time.npy\")\n",
    "        np.save(outfile, np.column_stack((times_bound, Mbound_arr)))\n",
    "        logging.info(f\"Bound mass results saved to {outfile}\")\n",
    "\n",
    "    return times_bound, Mbound_arr\n",
    "\n",
    "\n",
    "# Run the function and store results\n",
    "times_bound, Mbound_arr = compute_bound_mass_all_snaps(times_jacobi, rjacobi_arr)\n",
    "print(\"Cell 3.2.1 completed: M33 bound mass computed & stored for all snapshots.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8df8b0-6ccf-428b-b3c2-275556ece6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 3.2.2 — \"Bound Mass Timeseries Plots & Discussion\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_m33_bound_mass(times_bound, Mbound_arr, outfig=\"M33_bound_mass_vs_time.png\"):\n",
    "    \"\"\"\n",
    "    Plots M33's bound mass vs. time, optionally overlaid with textual commentary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    times_bound : np.ndarray\n",
    "        Times (Gyr)\n",
    "    Mbound_arr : np.ndarray\n",
    "        Bound mass (Msun)\n",
    "    outfig : str\n",
    "        Filename to save the figure. If None, won't save.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None. (Generates a plot and shows it.)\n",
    "    \"\"\"\n",
    "    if len(times_bound) == 0:\n",
    "        print(\"No M33 bound mass data to plot.\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    ax.plot(times_bound, Mbound_arr, '-', color='purple', label='M33 Bound Mass')\n",
    "\n",
    "    ax.set_xlabel(\"Time (Gyr)\")\n",
    "    ax.set_ylabel(\"M33 Bound Mass\")\n",
    "    ax.set_title(\"M33 Bound Mass Over Time\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Overplot a \"percentage lost\" annotation\n",
    "    initial_mass = Mbound_arr[0]\n",
    "    final_mass   = Mbound_arr[-1]\n",
    "    mass_loss_pct = 100.0 * (initial_mass - final_mass)/initial_mass if initial_mass>0 else 0\n",
    "\n",
    "    summary_text = (f\"Initial: {initial_mass:.2e}\\n\"\n",
    "                    f\"Final:   {final_mass:.2e}\\n\"\n",
    "                    f\"Lost ~ {mass_loss_pct:.1f}%\")\n",
    "\n",
    "    # place text somewhere on the plot\n",
    "    ax.text(0.05, 0.8, summary_text, transform=ax.transAxes,\n",
    "            fontsize=10, bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    if outfig:\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(PLOTS_DIRECTORY, exist_ok=True)\n",
    "        outfile = os.path.join(PLOTS_DIRECTORY, outfig)\n",
    "        plt.savefig(outfile, dpi=150)\n",
    "        print(f\"M33 bound mass plot saved to {outfile}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Extra commentary in the cell\n",
    "    print(\"Bound Mass Timeseries Discussion:\")\n",
    "    print(f\" - Initial Bound Mass: {initial_mass:.2e} Msun\")\n",
    "    print(f\" - Final Bound Mass:   {final_mass:.2e} Msun\")\n",
    "    print(f\" - Approx. {mass_loss_pct:.1f}% of M33's initial bound mass lost over the simulation.\\n\")\n",
    "\n",
    "\n",
    "# Plot the results from Cell 3.2.1\n",
    "plot_m33_bound_mass(times_bound, Mbound_arr, outfig=\"M33_bound_mass_vs_time.png\")\n",
    "\n",
    "print(\"Cell 3.2.2 completed: M33 bound mass plot & discussion generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efa66f1-358d-4db6-8966-1d956227d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 4.1.1 — \"Surface Density Profile Function & Single-Snapshot Demo\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "def surface_density_profile(x, y, mass, nbins=NBINS_PROFILES, rmax=RMAX_PROFILES):\n",
    "    \"\"\"\n",
    "    Creates a radial surface density profile from a set of M33 particles.\n",
    "    \n",
    "    Steps:\n",
    "      1) Compute R = sqrt(x^2 + y^2).\n",
    "      2) Accumulate mass in each radial annulus => Sigma(R).\n",
    "      3) Return (r_mid, Sigma).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : np.ndarray\n",
    "        Particle positions in kpc (already shifted so M33 is at (0,0) if needed).\n",
    "    mass : np.ndarray\n",
    "        Particle masses in '1e10 Msun' units or Msun (must be consistent).\n",
    "    nbins : int\n",
    "        Number of radial bins (default from NBINS_PROFILES).\n",
    "    rmax : float\n",
    "        Maximum radius in kpc (default from RMAX_PROFILES).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    r_mid : np.ndarray\n",
    "        Midpoint radius of each annulus (kpc).\n",
    "    Sigma : np.ndarray\n",
    "        Surface density in Msun/kpc^2 for each annulus.\n",
    "    \"\"\"\n",
    "    # Convert masses to Msun if they're in 1e10 Msun\n",
    "    # For clarity, let's assume mass is in 1e10 Msun from the snapshot file\n",
    "    # but if your code is storing them differently, adapt accordingly.\n",
    "    mass_in_Msun = mass * 1.0e10\n",
    "    \n",
    "    R = np.sqrt(x*x + y*y)\n",
    "    # Bin edges from 0..rmax\n",
    "    edges = np.linspace(0, rmax, nbins+1)\n",
    "    r_mid = 0.5 * (edges[:-1] + edges[1:])\n",
    "    \n",
    "    mass_in_bin = np.zeros(nbins)\n",
    "    \n",
    "    for i in range(nbins):\n",
    "        r_in = edges[i]\n",
    "        r_out = edges[i+1]\n",
    "        mask = (R >= r_in) & (R < r_out)\n",
    "        m_sum = mass_in_Msun[mask].sum()\n",
    "        mass_in_bin[i] = m_sum\n",
    "    \n",
    "    # Area of annulus = pi(R_out^2 - R_in^2)\n",
    "    area_bins = np.pi * (edges[1:]**2 - edges[:-1]**2)\n",
    "    Sigma = mass_in_bin / area_bins  # Msun / kpc^2\n",
    "    \n",
    "    return r_mid, Sigma\n",
    "\n",
    "\n",
    "# Demonstration: We'll pick a single snapshot, e.g. \"M33_000.txt\"\n",
    "# We'll parse it, find COM, shift the positions, compute surface density,\n",
    "# then plot (r_mid, Sigma).\n",
    "\n",
    "def demo_surface_density_single_snapshot(snap_index=0):\n",
    "    \"\"\"\n",
    "    Reads M33_<snap_index>.txt, centers on M33, computes (r_mid, Sigma),\n",
    "    and produces a quick plot for inspection.\n",
    "    \"\"\"\n",
    "    file_m33 = f\"{M33_DIRECTORY}M33_{snap_index:03d}.txt\"\n",
    "    from math import isnan\n",
    "\n",
    "    # parse M33\n",
    "    t_m33, count_m33, data_m33 = parse_galaxy_file(file_m33)\n",
    "    (ptype_m33, mass_m33, x_m33, y_m33, z_m33,\n",
    "     vx_m33, vy_m33, vz_m33) = data_m33\n",
    "\n",
    "    # Shift by M33 COM\n",
    "    xcom_m33, ycom_m33, zcom_m33 = center_of_mass(x_m33, y_m33, z_m33, mass_m33)\n",
    "    x_shift = x_m33 - xcom_m33\n",
    "    y_shift = y_m33 - ycom_m33\n",
    "    # ignoring z for 2D disk radial bins\n",
    "\n",
    "    # Compute profile\n",
    "    r_mid, Sigma = surface_density_profile(x_shift, y_shift, mass_m33)\n",
    "\n",
    "    # Quick log–log plot\n",
    "    fig, ax = plt.subplots(figsize=(12,5))\n",
    "    ax.loglog(r_mid, Sigma, '-', color='blue', label='Surface Density')\n",
    "\n",
    "    ax.set_xlabel(\"R (kpc) [log scale]\")\n",
    "    ax.set_ylabel(r\"$\\Sigma(R)$ (Msun kpc$^{-2}$) [log scale]\")\n",
    "    ax.set_title(f\"M33 Snapshot {snap_index:03d} (t={t_m33:.2f} Gyr)\")\n",
    "    ax.legend()\n",
    "\n",
    "    # Optionally, save the figure\n",
    "    os.makedirs(PLOTS_DIRECTORY, exist_ok=True)\n",
    "    outfig = os.path.join(PLOTS_DIRECTORY, f\"M33_{snap_index:03d}_SurfaceDensityDemo.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outfig, dpi=150)\n",
    "    print(f\"Surface density demo plot saved to {outfig}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Print a quick summary\n",
    "    logging.info(f\"demo_surface_density_single_snapshot: snapshot={snap_index}, time={t_m33:.3f} Gyr, \"\n",
    "                 f\"max Sigma ~ {Sigma.max():.2e} Msun/kpc^2, out to {r_mid[-1]:.1f} kpc\")\n",
    "\n",
    "# Run the demonstration for snapshot 0\n",
    "demo_surface_density_single_snapshot(snap_index=0)\n",
    "print(\"Cell 4.1.1 completed: surface_density_profile() defined and single-snapshot demo done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e51d26-ac2d-4f03-b71b-97017d9bfd93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 4.1.2 — \"Surface Density Profiles for All Snapshots\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import glob\n",
    "import logging\n",
    "\n",
    "def generate_all_surface_density_profiles(\n",
    "    nbins=NBINS_PROFILES, rmax=RMAX_PROFILES,\n",
    "    save_results=SAVE_INTERMEDIATE_RESULTS\n",
    "):\n",
    "    \"\"\"\n",
    "    Loops over M33_*.txt snapshots, does the same routine:\n",
    "    1) parse M33\n",
    "    2) shift x,y by COM\n",
    "    3) compute (r_mid, Sigma) via surface_density_profile()\n",
    "    4) store results in a dict => profiles[snap] = (time, r_mid, Sigma)\n",
    "\n",
    "    Optionally saves them to .npy or .csv for external usage.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    profiles : dict\n",
    "      Key: snapshot index (int),\n",
    "      Value: (time[Gyr], r_mid array, Sigma array).\n",
    "    \"\"\"\n",
    "    m33_files = sorted(glob.glob(f\"{M33_DIRECTORY}M33_*.txt\"))\n",
    "    profiles = {}\n",
    "\n",
    "    for f in m33_files:\n",
    "        snap_idx = get_snapshot_index(f)\n",
    "        if snap_idx is None:\n",
    "            continue\n",
    "\n",
    "        # parse\n",
    "        t_m33, count_m33, data_m33 = parse_galaxy_file(f)\n",
    "        (ptype, mass, x, y, z, vx, vy, vz) = data_m33\n",
    "\n",
    "        # COM\n",
    "        xcom, ycom, zcom = center_of_mass(x, y, z, mass)\n",
    "        x_shift = x - xcom\n",
    "        y_shift = y - ycom\n",
    "\n",
    "        # Surface density\n",
    "        r_mid, Sigma = surface_density_profile(x_shift, y_shift, mass,\n",
    "                                               nbins=nbins, rmax=rmax)\n",
    "\n",
    "        # store\n",
    "        profiles[snap_idx] = (t_m33, r_mid, Sigma)\n",
    "\n",
    "        # Inline check for suspicious values\n",
    "        if np.isnan(Sigma).any() or Sigma.max() > 1e12:\n",
    "            logging.warning(f\"Snapshot {snap_idx}: suspicious Sigma max: {Sigma.max():.2e} Msun/kpc^2\")\n",
    "\n",
    "    # Optionally save\n",
    "    if save_results and len(profiles) > 0:\n",
    "        os.makedirs(RESULTS_DIRECTORY, exist_ok=True)\n",
    "        # We'll just store them in a .npz (NumPy zipped) for convenience\n",
    "        outfn = os.path.join(RESULTS_DIRECTORY, \"all_surface_density_profiles.npz\")\n",
    "\n",
    "        savez_dict = {}\n",
    "        for snap_idx, (t_val, r_mid, Sigma) in profiles.items():\n",
    "            savez_dict[f\"Snap{snap_idx}_time\"] = np.array([t_val])\n",
    "            savez_dict[f\"Snap{snap_idx}_rmid\"] = r_mid\n",
    "            savez_dict[f\"Snap{snap_idx}_Sigma\"] = Sigma\n",
    "        np.savez(outfn, **savez_dict)\n",
    "        logging.info(f\"All surface density profiles saved to {outfn}\")\n",
    "\n",
    "    return profiles\n",
    "\n",
    "\n",
    "# Generate the profiles and store in memory\n",
    "all_profiles = generate_all_surface_density_profiles()\n",
    "print(\"Cell 4.1.2 completed: surface density profiles generated for all snapshots.\")\n",
    "print(f\"Number of snapshots processed: {len(all_profiles)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d57ed0c-2f28-46dd-b74f-0614d8fffbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 4.2.1 — \"Define Fitting Routines\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import logging\n",
    "\n",
    "def sersic_profile(R, Sigma_e, Re, n):\n",
    "    \"\"\"\n",
    "    Returns the Sersic surface density profile for input radius array R.\n",
    "\n",
    "    Sersic formula (projected):\n",
    "        Sigma(R) = Sigma_e * exp( - b_n * [ (R/Re)^(1/n) - 1 ] )\n",
    "\n",
    "    where b_n is commonly approximated as:\n",
    "        b_n = 1.9992*n - 0.3271   (for 0.5 < n < ~10)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    R : np.ndarray\n",
    "        Array of radii (kpc).\n",
    "    Sigma_e : float\n",
    "        Surface density at R=Re (Msun/kpc^2).\n",
    "    Re : float\n",
    "        Effective (half-mass) radius in kpc.\n",
    "    n : float\n",
    "        Sersic index.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Sigma : np.ndarray\n",
    "        Surface density (Msun/kpc^2) at each R.\n",
    "    \"\"\"\n",
    "    # Keep R as array\n",
    "    R = np.array(R, dtype=float)\n",
    "\n",
    "    # compute b_n\n",
    "    b_n = 1.9992*n - 0.3271  # approximation from Ciotti & Bertin (1999)\n",
    "    # handle edge cases\n",
    "    b_n = max(b_n, 0.001)\n",
    "\n",
    "    term = (R/Re)**(1./n) - 1.0\n",
    "    return Sigma_e * np.exp(-b_n * term)\n",
    "\n",
    "\n",
    "def exponential_profile(R, Sigma0, h):\n",
    "    \"\"\"\n",
    "    Returns the exponential disk surface density profile for input radius array R.\n",
    "\n",
    "    Exponential profile:\n",
    "        Sigma(R) = Sigma0 * exp(-R/h)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    R : np.ndarray\n",
    "        Radii (kpc).\n",
    "    Sigma0 : float\n",
    "        Central surface density in Msun/kpc^2.\n",
    "    h : float\n",
    "        Scale length in kpc.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Sigma : np.ndarray\n",
    "        Surface density (Msun/kpc^2).\n",
    "    \"\"\"\n",
    "    R = np.array(R, dtype=float)\n",
    "    return Sigma0 * np.exp(-R/h)\n",
    "\n",
    "\n",
    "def fit_sersic(rvals, sigma_vals):\n",
    "    \"\"\"\n",
    "    Fit the Sersic profile to (rvals, sigma_vals).\n",
    "\n",
    "    We'll do a simple least-squares fit using scipy's curve_fit.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rvals : np.ndarray\n",
    "        Radii in kpc.\n",
    "    sigma_vals : np.ndarray\n",
    "        Surface density (Msun/kpc^2).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (Sigma_e, Re, n) : tuple of floats\n",
    "        Best-fit Sersic parameters. If fit fails, returns (nan, nan, nan).\n",
    "    \"\"\"\n",
    "    # filter out zeros or negative for stable fitting\n",
    "    mask = (rvals > 0) & (sigma_vals > 0)\n",
    "    r_fit = rvals[mask]\n",
    "    s_fit = sigma_vals[mask]\n",
    "\n",
    "    if len(r_fit) < 5:\n",
    "        logging.warning(\"fit_sersic: Not enough data points to fit.\")\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "\n",
    "    # initial guesses\n",
    "    guess_Sigma_e = np.median(s_fit)  # rough middle\n",
    "    guess_Re      = r_fit[len(r_fit)//2] if len(r_fit) > 1 else 5.0\n",
    "    guess_n       = 1.0\n",
    "\n",
    "    try:\n",
    "        popt, pcov = curve_fit(sersic_profile, r_fit, s_fit,\n",
    "                               p0=[guess_Sigma_e, guess_Re, guess_n],\n",
    "                               maxfev=2000)\n",
    "        # popt -> [Sigma_e, Re, n]\n",
    "        return (popt[0], popt[1], popt[2])\n",
    "    except RuntimeError:\n",
    "        logging.warning(\"fit_sersic: Curve fit did not converge.\")\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "\n",
    "\n",
    "def fit_exponential(rvals, sigma_vals):\n",
    "    \"\"\"\n",
    "    Fit the exponential profile: Sigma(R) = Sigma0 * exp(-R/h).\n",
    "\n",
    "    Returns (Sigma0, h).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rvals : np.ndarray\n",
    "        Radii (kpc)\n",
    "    sigma_vals : np.ndarray\n",
    "        Surface density (Msun/kpc^2).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (Sigma0, h) : tuple\n",
    "        Best-fit exponential parameters. If fit fails, returns (nan, nan).\n",
    "    \"\"\"\n",
    "    # filter out zeros or negative for stable fitting\n",
    "    mask = (rvals > 0) & (sigma_vals > 0)\n",
    "    r_fit = rvals[mask]\n",
    "    s_fit = sigma_vals[mask]\n",
    "\n",
    "    if len(r_fit) < 5:\n",
    "        logging.warning(\"fit_exponential: Not enough data points to fit.\")\n",
    "        return (np.nan, np.nan)\n",
    "\n",
    "    guess_Sigma0 = np.max(s_fit)\n",
    "    guess_h      = 2.0\n",
    "\n",
    "    try:\n",
    "        popt, pcov = curve_fit(exponential_profile, r_fit, s_fit,\n",
    "                               p0=[guess_Sigma0, guess_h],\n",
    "                               maxfev=2000)\n",
    "        # popt -> [Sigma0, h]\n",
    "        return (popt[0], popt[1])\n",
    "    except RuntimeError:\n",
    "        logging.warning(\"fit_exponential: Curve fit did not converge.\")\n",
    "        return (np.nan, np.nan)\n",
    "\n",
    "\n",
    "print(\"Cell 4.2.1 completed: Sersic & Exponential fitting routines defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8f369b-120c-403f-a68d-4f3ae2cc573b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 4.2.2 — \"Run Fits for All Snapshots & Store Best-Fit Parameters\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "def run_fits_for_all_snapshots(all_profiles,\n",
    "                               save_results=SAVE_INTERMEDIATE_RESULTS):\n",
    "    \"\"\"\n",
    "    For each snapshot in all_profiles, do:\n",
    "       - Sersic fit => sersic_fits[snap_idx] = (time, Sigma_e, Re, n)\n",
    "       - Exponential fit => exp_fits[snap_idx] = (time, Sigma0, h)\n",
    "\n",
    "    Provide logs if a fit fails or yields suspicious values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_profiles : dict\n",
    "        From generate_all_surface_density_profiles().\n",
    "        Key: snapshot index -> (time[Gyr], r_mid array, Sigma array)\n",
    "\n",
    "    save_results : bool\n",
    "        If True, will save these results to .npy in results/ directory.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sersic_fits : dict\n",
    "       snap_idx -> (time, Sigma_e, Re, n)\n",
    "    exp_fits : dict\n",
    "       snap_idx -> (time, Sigma0, h)\n",
    "    \"\"\"\n",
    "    sersic_fits = {}\n",
    "    exp_fits    = {}\n",
    "\n",
    "    for snap_idx in sorted(all_profiles.keys()):\n",
    "        t_val, r_mid, Sigma = all_profiles[snap_idx]\n",
    "\n",
    "        (Sigma_e, Re, n) = fit_sersic(r_mid, Sigma)\n",
    "        (Sigma0, h)      = fit_exponential(r_mid, Sigma)\n",
    "\n",
    "        sersic_fits[snap_idx] = (t_val, Sigma_e, Re, n)\n",
    "        exp_fits[snap_idx]    = (t_val, Sigma0, h)\n",
    "\n",
    "        # Logging checks\n",
    "        if np.isnan(Re) or np.isnan(n):\n",
    "            logging.warning(f\"Snapshot {snap_idx}: Sersic fit returned NaNs.\")\n",
    "        if np.isnan(Sigma0) or np.isnan(h):\n",
    "            logging.warning(f\"Snapshot {snap_idx}: Exponential fit returned NaNs.\")\n",
    "        \n",
    "        logging.info(f\"Snap {snap_idx}: time={t_val:.2f} Gyr => Sersic(Re={Re:.2f}, n={n:.2f}), \"\n",
    "                     f\"Exp(h={h:.2f})\")\n",
    "\n",
    "    # Optionally save to .npy\n",
    "    if save_results and len(all_profiles) > 0:\n",
    "        os.makedirs(RESULTS_DIRECTORY, exist_ok=True)\n",
    "        # We'll store them as two separate .npy or .npz\n",
    "        # For quick usage, we'll do .npz again:\n",
    "        sersic_out = os.path.join(RESULTS_DIRECTORY, \"sersic_fits.npz\")\n",
    "        exp_out    = os.path.join(RESULTS_DIRECTORY, \"exp_fits.npz\")\n",
    "\n",
    "        # We'll flatten them into arrays or store them as dictionaries:\n",
    "        # We'll store each snap as SnapXXX_time, SnapXXX_SigmaE, SnapXXX_Re, SnapXXX_n, etc.\n",
    "        sersic_dict = {}\n",
    "        exp_dict = {}\n",
    "        for snap_idx in sersic_fits.keys():\n",
    "            t_val, Se, re_, n_ = sersic_fits[snap_idx]\n",
    "            sersic_dict[f\"Snap{snap_idx}_time\"]   = np.array([t_val])\n",
    "            sersic_dict[f\"Snap{snap_idx}_SigmaE\"] = np.array([Se])\n",
    "            sersic_dict[f\"Snap{snap_idx}_Re\"]     = np.array([re_])\n",
    "            sersic_dict[f\"Snap{snap_idx}_n\"]      = np.array([n_])\n",
    "\n",
    "            t_val2, S0, h_ = exp_fits[snap_idx]\n",
    "            exp_dict[f\"Snap{snap_idx}_time\"]   = np.array([t_val2])\n",
    "            exp_dict[f\"Snap{snap_idx}_Sigma0\"] = np.array([S0])\n",
    "            exp_dict[f\"Snap{snap_idx}_h\"]      = np.array([h_])\n",
    "\n",
    "        np.savez(sersic_out, **sersic_dict)\n",
    "        np.savez(exp_out, **exp_dict)\n",
    "        logging.info(f\"Sersic fits saved to {sersic_out}\")\n",
    "        logging.info(f\"Exp fits saved to {exp_out}\")\n",
    "\n",
    "    return sersic_fits, exp_fits\n",
    "\n",
    "\n",
    "# We'll call this on the dictionary 'all_profiles' from Cell 4.1.2\n",
    "sersic_fits, exp_fits = run_fits_for_all_snapshots(all_profiles)\n",
    "print(\"Cell 4.2.2 completed: best-fit parameters (Sersic & exponential) computed & stored.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f83d64-512a-4808-8d6c-ef3e7a6c702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 4.2.3 — \"Timeseries of Fit Parameters: Re, n, Scale Length, etc.\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_fit_parameters_timeseries(sersic_fits, exp_fits,\n",
    "                                   outfig=\"sersic_exp_timeseries.png\"):\n",
    "    \"\"\"\n",
    "    Generate plots of time vs. Re, time vs. n (Sersic),\n",
    "    and time vs. scale length h (Exponential). \n",
    "\n",
    "    We'll do a 3-panel figure:\n",
    "    - Panel 1: time vs. Re\n",
    "    - Panel 2: time vs. n\n",
    "    - Panel 3: time vs. h\n",
    "\n",
    "    If needed, we can do time vs. Sigma_e or Sigma0 as well, but let's keep it simpler.\n",
    "    \"\"\"\n",
    "    if not sersic_fits and not exp_fits:\n",
    "        print(\"No fit data found. Skipping timeseries plots.\")\n",
    "        return\n",
    "\n",
    "    # We'll gather all snapshot indices from sersic_fits\n",
    "    sersic_snaps = sorted(sersic_fits.keys())\n",
    "    exp_snaps    = sorted(exp_fits.keys())\n",
    "\n",
    "    # Build arrays for plotting\n",
    "    times_sersic = []\n",
    "    Re_arr  = []\n",
    "    n_arr   = []\n",
    "    for snap in sersic_snaps:\n",
    "        t_val, Sigma_e, Re, n_ = sersic_fits[snap]\n",
    "        times_sersic.append(t_val)\n",
    "        Re_arr.append(Re)\n",
    "        n_arr.append(n_)\n",
    "\n",
    "    times_exp = []\n",
    "    h_arr = []\n",
    "    for snap in exp_snaps:\n",
    "        t_val2, Sigma0, h_ = exp_fits[snap]\n",
    "        times_exp.append(t_val2)\n",
    "        h_arr.append(h_)\n",
    "\n",
    "    # Convert to arrays, sort by time if needed\n",
    "    times_sersic = np.array(times_sersic)\n",
    "    Re_arr       = np.array(Re_arr)\n",
    "    n_arr        = np.array(n_arr)\n",
    "\n",
    "    times_exp = np.array(times_exp)\n",
    "    h_arr     = np.array(h_arr)\n",
    "\n",
    "    # Sort them\n",
    "    s_idx = np.argsort(times_sersic)\n",
    "    e_idx = np.argsort(times_exp)\n",
    "    times_sersic = times_sersic[s_idx]\n",
    "    Re_arr = Re_arr[s_idx]\n",
    "    n_arr  = n_arr[s_idx]\n",
    "\n",
    "    times_exp = times_exp[e_idx]\n",
    "    h_arr     = h_arr[e_idx]\n",
    "\n",
    "    # We'll unify the times if they match:\n",
    "    # For clarity, let's just do separate lines or subplots.\n",
    "\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(15,15))\n",
    "    # Panel 1: Re\n",
    "    axs[0].plot(times_sersic, Re_arr, '-', color='blue')\n",
    "    axs[0].set_xlabel(\"Time (Gyr)\")\n",
    "    axs[0].set_ylabel(\"Re (kpc)\")\n",
    "    axs[0].set_title(\"Sersic Effective Radius vs. Time\")\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # Panel 2: n\n",
    "    axs[1].plot(times_sersic, n_arr, '-', color='green')\n",
    "    axs[1].set_xlabel(\"Time (Gyr)\")\n",
    "    axs[1].set_ylabel(\"Sersic Index n\")\n",
    "    axs[1].set_title(\"Sersic n vs. Time\")\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    # Panel 3: h\n",
    "    axs[2].plot(times_exp, h_arr, '-', color='purple')\n",
    "    axs[2].set_xlabel(\"Time (Gyr)\")\n",
    "    axs[2].set_ylabel(\"Scale Length h (kpc)\")\n",
    "    axs[2].set_title(\"Exponential Scale Length vs. Time\")\n",
    "    axs[2].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if outfig:\n",
    "        os.makedirs(PLOTS_DIRECTORY, exist_ok=True)\n",
    "        outfile = os.path.join(PLOTS_DIRECTORY, outfig)\n",
    "        plt.savefig(outfile, dpi=150)\n",
    "        print(f\"Timeseries of fit parameters saved to {outfile}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Some textual commentary about changes\n",
    "    if len(Re_arr) > 1:\n",
    "        # e.g. check if there's a drop near half the simulation\n",
    "        initial_Re = Re_arr[0]\n",
    "        final_Re   = Re_arr[-1]\n",
    "        change_pct = 100.0 * (final_Re - initial_Re)/initial_Re if initial_Re>0 else 0\n",
    "        print(f\"\\nSersic Re changed from {initial_Re:.2f} kpc to {final_Re:.2f} kpc, ~{change_pct:.1f}% change.\")\n",
    "\n",
    "    if len(h_arr) > 1:\n",
    "        # similarly for h\n",
    "        initial_h = h_arr[0]\n",
    "        final_h   = h_arr[-1]\n",
    "        change_pct_h = 100.0*(final_h - initial_h)/initial_h if initial_h>0 else 0\n",
    "        print(f\"Exponential scale length h changed from {initial_h:.2f} to {final_h:.2f} (~{change_pct_h:.1f}%).\")\n",
    "\n",
    "    print(\"\\nCell 4.2.3 completed: timeseries of Sersic/Exponential parameters plotted.\\n\")\n",
    "\n",
    "\n",
    "# Now we call the function to visualize the results\n",
    "plot_fit_parameters_timeseries(sersic_fits, exp_fits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e48bc7-b728-488e-8990-d8c1441bef1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 4.3.1 — \"Slope-based Tidal Truncation Analysis\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "def find_truncation_radius(rvals, sigma_vals, slope_threshold=-4.0):\n",
    "    \"\"\"\n",
    "    Given arrays (rvals, sigma_vals), compute the log–log slope\n",
    "    of the surface density profile. We'll define the truncation radius\n",
    "    as the first radius where d(log Sigma)/d(log R) < slope_threshold.\n",
    "    \n",
    "    If not found, return None or np.nan.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rvals : np.ndarray\n",
    "        Radii in kpc\n",
    "    sigma_vals : np.ndarray\n",
    "        Surface density in Msun/kpc^2\n",
    "    slope_threshold : float\n",
    "        The slope below which we claim 'tidal truncation' (default -4.0).\n",
    "        i.e. if slope < -4, we say it's truncated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    R_trunc : float or None\n",
    "        The radius in kpc of the first annulus midpoint that meets slope < slope_threshold.\n",
    "        If no truncation found, returns np.nan.\n",
    "    \"\"\"\n",
    "    # Filter valid data\n",
    "    mask = (rvals > 0) & (sigma_vals > 0)\n",
    "    r_ok = rvals[mask]\n",
    "    s_ok = sigma_vals[mask]\n",
    "    if len(r_ok) < 3:\n",
    "        # Not enough data\n",
    "        return np.nan\n",
    "\n",
    "    # Compute log10(R), log10(Sigma)\n",
    "    logR = np.log10(r_ok)\n",
    "    logS = np.log10(s_ok)\n",
    "\n",
    "    # We'll compute slope in between bin i and i+1\n",
    "    # slope_i = [ d(logS)/d(logR) ] ~ ( logS[i+1]-logS[i] ) / ( logR[i+1]-logR[i] )\n",
    "    slopes = []\n",
    "    rmid = []\n",
    "    for i in range(len(r_ok)-1):\n",
    "        dlogS = logS[i+1] - logS[i]\n",
    "        dlogR = logR[i+1] - logR[i]\n",
    "        if abs(dlogR) < 1e-8:\n",
    "            continue\n",
    "        slope_i = dlogS / dlogR\n",
    "        slopes.append(slope_i)\n",
    "        # midpoint in radius (linear, not log)\n",
    "        # or we can do 10^(mean(logR[i], logR[i+1])) \n",
    "        # Let's do linear midpoint for interpretability:\n",
    "        rmid_i = 0.5*(r_ok[i] + r_ok[i+1])\n",
    "        rmid.append(rmid_i)\n",
    "\n",
    "    slopes = np.array(slopes)\n",
    "    rmid = np.array(rmid)\n",
    "    if len(slopes) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    # find first place where slope < slope_threshold\n",
    "    idx = np.where(slopes < slope_threshold)[0]\n",
    "    if len(idx) == 0:\n",
    "        return np.nan\n",
    "    i_first = idx[0]\n",
    "    return rmid[i_first]\n",
    "\n",
    "\n",
    "def compute_tidal_truncation(all_profiles, slope_threshold=-4.0, save_results=SAVE_INTERMEDIATE_RESULTS):\n",
    "    \"\"\"\n",
    "    Loop over the surface density profiles in 'all_profiles', \n",
    "    for each snapshot compute the 'tidal truncation' radius based on slope_threshold.\n",
    "\n",
    "    all_profiles : dict\n",
    "       snap_idx -> (time, r_mid, Sigma)\n",
    "    slope_threshold : float\n",
    "       e.g. -4.0 or -5.0 to define 'tidal truncation'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    times_trunc : np.ndarray\n",
    "        times in Gyr\n",
    "    Rtrunc_arr : np.ndarray\n",
    "        truncation radius in kpc\n",
    "    \"\"\"\n",
    "    snap_indices = sorted(all_profiles.keys())\n",
    "    times_trunc = []\n",
    "    Rtrunc_arr  = []\n",
    "\n",
    "    for snap_idx in snap_indices:\n",
    "        t_val, r_mid, Sigma = all_profiles[snap_idx]\n",
    "        R_trunc = find_truncation_radius(r_mid, Sigma, slope_threshold=slope_threshold)\n",
    "        if np.isnan(R_trunc):\n",
    "            logging.info(f\"Snapshot {snap_idx}: No truncation found or insufficient data.\")\n",
    "        else:\n",
    "            logging.info(f\"Snapshot {snap_idx}: Tidal truncation radius = {R_trunc:.2f} kpc (slope<{slope_threshold})\")\n",
    "\n",
    "        times_trunc.append(t_val)\n",
    "        Rtrunc_arr.append(R_trunc)\n",
    "\n",
    "    times_trunc = np.array(times_trunc)\n",
    "    Rtrunc_arr  = np.array(Rtrunc_arr)\n",
    "\n",
    "    # Sort by time\n",
    "    sort_idx = np.argsort(times_trunc)\n",
    "    times_trunc = times_trunc[sort_idx]\n",
    "    Rtrunc_arr  = Rtrunc_arr[sort_idx]\n",
    "\n",
    "    # Optional save\n",
    "    if save_results and len(times_trunc) > 0:\n",
    "        import os\n",
    "        os.makedirs(RESULTS_DIRECTORY, exist_ok=True)\n",
    "        outfile = os.path.join(RESULTS_DIRECTORY, \"tidal_truncation_vs_time.npy\")\n",
    "        np.save(outfile, np.column_stack((times_trunc, Rtrunc_arr)))\n",
    "        logging.info(f\"Tidal truncation results saved to {outfile}\")\n",
    "\n",
    "    return times_trunc, Rtrunc_arr\n",
    "\n",
    "\n",
    "# We'll run the slope-based truncation with a default threshold of -4.0\n",
    "times_trunc, Rtrunc_arr = compute_tidal_truncation(all_profiles, slope_threshold=-4.0)\n",
    "print(\"Cell 4.3.1 completed: slope-based tidal truncation analysis done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82826f41-53fc-4839-9264-c833c4048612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 4.3.2 — \"Plot Tidal Truncation Radius vs. Time\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "def plot_tidal_truncation_vs_time(times_trunc, Rtrunc_arr,\n",
    "                                  times_jacobi=None, rjacobi_arr=None,\n",
    "                                  slope_threshold=-4.0,\n",
    "                                  outfig=\"tidal_truncation_vs_time.png\"):\n",
    "    \"\"\"\n",
    "    Plots (time, R_trunc) from slope-based truncation analysis.\n",
    "    Optionally overlays Jacobi radius vs. time for comparison.\n",
    "\n",
    "    times_trunc, Rtrunc_arr : np.ndarray\n",
    "        The arrays from compute_tidal_truncation()\n",
    "    times_jacobi, rjacobi_arr : np.ndarray or None\n",
    "        If provided, we overlay the Jacobi radius. \n",
    "    slope_threshold : float\n",
    "        The slope used to define truncation. We'll mention in the title.\n",
    "    outfig : str\n",
    "        Filename for saving the plot. If None, won't save.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "\n",
    "    if len(times_trunc) == 0:\n",
    "        print(\"No tidal truncation data to plot.\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    ax.plot(times_trunc, Rtrunc_arr, '-', color='red', label='Tidal Truncation Radius')\n",
    "\n",
    "    # Overlay Jacobi radius if provided\n",
    "    if times_jacobi is not None and rjacobi_arr is not None and len(times_jacobi) == len(rjacobi_arr) and len(times_jacobi)>0:\n",
    "        # We might want to re-sort times_jacobi in ascending order\n",
    "        idx_j = np.argsort(times_jacobi)\n",
    "        t_j_sorted = times_jacobi[idx_j]\n",
    "        r_j_sorted = rjacobi_arr[idx_j]\n",
    "        ax.plot(t_j_sorted, r_j_sorted, '-', color='blue', alpha=0.6, label='Jacobi Radius')\n",
    "\n",
    "    ax.set_xlabel(\"Time (Gyr)\")\n",
    "    ax.set_ylabel(\"Radius (kpc)\")\n",
    "    ax.set_title(f\"Tidal Truncation vs. Time (slope<{slope_threshold})\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "    # Save figure if desired\n",
    "    if outfig:\n",
    "        os.makedirs(PLOTS_DIRECTORY, exist_ok=True)\n",
    "        outfile = os.path.join(PLOTS_DIRECTORY, outfig)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outfile, dpi=150)\n",
    "        print(f\"Tidal truncation plot saved to {outfile}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# We'll call the plotting function. We'll pass times_jacobi, rjacobi_arr from Section 3.1 for overlay if we want:\n",
    "plot_tidal_truncation_vs_time(times_trunc, Rtrunc_arr, \n",
    "                              times_jacobi, rjacobi_arr,\n",
    "                              slope_threshold=-4.0,\n",
    "                              outfig=\"tidal_truncation_vs_time.png\")\n",
    "\n",
    "print(\"Cell 4.3.2 completed: tidal truncation radius vs. time plot generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2d275-d8ec-4cb7-9aef-ebfd5cf8620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 5.1.1 — \"Rotation + 2D Histograms: Single Snapshot Demo\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "def rotate_frame(pos, vel):\n",
    "    \"\"\"\n",
    "    Rotate the coordinate system so that the disk's angular momentum vector \n",
    "    is aligned with the +z axis.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pos : np.ndarray of shape (N,3)\n",
    "        3D positions (x,y,z) in kpc.\n",
    "    vel : np.ndarray of shape (N,3)\n",
    "        3D velocities (vx,vy,vz) in km/s (or consistent unit).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pos_rot : np.ndarray of shape (N,3)\n",
    "        Rotated positions.\n",
    "    vel_rot : np.ndarray of shape (N,3)\n",
    "        Rotated velocities.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    We compute the total angular momentum L = sum(r x v) over all particles,\n",
    "    then define a rotation that maps L to z-hat using Rodrigues' formula.\n",
    "    \"\"\"\n",
    "    # compute angular momentum\n",
    "    # L = sum(r_i x v_i), axis=0 => vector\n",
    "    L = np.sum(np.cross(pos, vel), axis=0)\n",
    "    L_mag = np.sqrt(np.sum(L**2))\n",
    "    if L_mag == 0:\n",
    "        # fallback\n",
    "        logging.warning(\"rotate_frame: Angular momentum is zero. No rotation applied.\")\n",
    "        return pos, vel\n",
    "\n",
    "    L_norm = L / L_mag\n",
    "\n",
    "    # We want to map L_norm to z-hat => (0,0,1)\n",
    "    z_hat = np.array([0,0,1], dtype=float)\n",
    "\n",
    "    # cross product\n",
    "    v = np.cross(L_norm, z_hat)\n",
    "    s = np.sqrt(np.sum(v**2))\n",
    "    c = np.dot(L_norm, z_hat)\n",
    "\n",
    "    # if s ~ 0 => L is already aligned with z\n",
    "    if s < 1e-8:\n",
    "        return pos, vel\n",
    "\n",
    "    # Rodrigues rotation formula\n",
    "    I  = np.eye(3)\n",
    "    vx = np.array([[0,      -v[2],   v[1]],\n",
    "                   [v[2],   0,      -v[0]],\n",
    "                   [-v[1],  v[0],    0   ]])\n",
    "    \n",
    "    R = I + vx + (vx @ vx)*((1 - c)/(s**2))\n",
    "\n",
    "    pos_rot = (R @ pos.T).T\n",
    "    vel_rot = (R @ vel.T).T\n",
    "\n",
    "    return pos_rot, vel_rot\n",
    "\n",
    "\n",
    "def demo_face_edge_on(snapshot_index=0, filter_disk=False, disk_type=2):\n",
    "    \"\"\"\n",
    "    Demonstrates how to:\n",
    "      1) pick M33 snapshot,\n",
    "      2) parse & center on M33,\n",
    "      3) optionally filter 'disk' particles (if filter_disk=True, we pick type=2),\n",
    "      4) rotate coords so disk angular momentum is along +z,\n",
    "      5) produce face-on & edge-on 2D histograms.\n",
    "    \n",
    "    The plots are displayed inline and saved in 'plots/' directory.\n",
    "    \"\"\"\n",
    "    # parse\n",
    "    file_m33 = f\"{M33_DIRECTORY}M33_{snapshot_index:03d}.txt\"\n",
    "    t_m33, count_m33, data_m33 = parse_galaxy_file(file_m33)\n",
    "    (ptype, mass, x, y, z, vx, vy, vz) = data_m33\n",
    "\n",
    "    # shift by M33 COM\n",
    "    xcom, ycom, zcom = center_of_mass(x, y, z, mass)\n",
    "    x_shift = x - xcom\n",
    "    y_shift = y - ycom\n",
    "    z_shift = z - zcom\n",
    "\n",
    "    vx_shift = vx  # We might shift velocities by M33 COM velocity if needed\n",
    "    vy_shift = vy\n",
    "    vz_shift = vz\n",
    "\n",
    "    # optionally filter disk\n",
    "    if filter_disk:\n",
    "        disk_mask = (ptype == disk_type)\n",
    "        x_shift = x_shift[disk_mask]\n",
    "        y_shift = y_shift[disk_mask]\n",
    "        z_shift = z_shift[disk_mask]\n",
    "        vx_shift = vx_shift[disk_mask]\n",
    "        vy_shift = vy_shift[disk_mask]\n",
    "        vz_shift = vz_shift[disk_mask]\n",
    "\n",
    "    # combine pos, vel for rotation\n",
    "    pos_arr = np.column_stack((x_shift, y_shift, z_shift))\n",
    "    vel_arr = np.column_stack((vx_shift, vy_shift, vz_shift))\n",
    "\n",
    "    # rotate\n",
    "    pos_rot, vel_rot = rotate_frame(pos_arr, vel_arr)\n",
    "\n",
    "    # face-on => (x_rot, y_rot)\n",
    "    # edge-on => (x_rot, z_rot) or (y_rot, z_rot)\n",
    "    x_rot = pos_rot[:,0]\n",
    "    y_rot = pos_rot[:,1]\n",
    "    z_rot = pos_rot[:,2]\n",
    "\n",
    "    # 2D hist face-on\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "    nbins = 150\n",
    "    h1 = ax1.hist2d(x_rot, y_rot, bins=nbins, cmap='magma')\n",
    "    ax1.set_xlabel(\"x (kpc)\")\n",
    "    ax1.set_ylabel(\"y (kpc)\")\n",
    "    ax1.set_title(f\"M33 Snap {snapshot_index:03d} Face-On (t={t_m33:.2f} Gyr)\")\n",
    "    ax1.set_aspect('equal', 'box')\n",
    "\n",
    "    # edge-on (x,z)\n",
    "    h2 = ax2.hist2d(x_rot, z_rot, bins=nbins, cmap='magma')\n",
    "    ax2.set_xlabel(\"x (kpc)\")\n",
    "    ax2.set_ylabel(\"z (kpc)\")\n",
    "    ax2.set_title(f\"Edge-On View\")\n",
    "    ax2.set_aspect('equal', 'box')\n",
    "\n",
    "    fig.colorbar(h1[3], ax=ax1, label=\"Counts\")\n",
    "    fig.colorbar(h2[3], ax=ax2, label=\"Counts\")\n",
    "\n",
    "    # save\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(PLOTS_DIRECTORY, exist_ok=True)\n",
    "    outfig = os.path.join(PLOTS_DIRECTORY, f\"M33_{snapshot_index:03d}_MorphDemo.png\")\n",
    "    plt.savefig(outfig, dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    logging.info(f\"demo_face_edge_on: Generated morphological plots for snapshot {snapshot_index}\")\n",
    "\n",
    "\n",
    "# Let's do a single snapshot demo with or without filtering\n",
    "demo_face_edge_on(snapshot_index=0, filter_disk=True)\n",
    "print(\"Cell 5.1.1 completed: single-snapshot morphological demo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa8c46-b679-43dc-b7d5-c83913e28c13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 5.1.2 — \"Automated Morphology Plots for All Snapshots (Side-by-Side)\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "import glob\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def generate_morphology_plots_all_snaps_side_by_side(filter_disk=True, disk_type=2):\n",
    "    \"\"\"\n",
    "    Loops over M33 snapshots, applies coordinate rotation so the disk is face-on,\n",
    "    and saves a single image with two subplots side by side (12x6):\n",
    "      - Left  => Face-On (x vs. y)\n",
    "      - Right => Edge-On (x vs. z)\n",
    "\n",
    "    The resulting figure is saved as 'plots/M33_morph_<snap>.png'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filter_disk : bool\n",
    "        If True, only use particles with type == disk_type\n",
    "    disk_type : int\n",
    "        The particle type for the 'disk' (commonly 2)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None (plots are generated & saved)\n",
    "    \"\"\"\n",
    "    # Find all M33 snapshot files\n",
    "    m33_files = sorted(glob.glob(f\"{M33_DIRECTORY}M33_*.txt\"))\n",
    "\n",
    "    for f in m33_files:\n",
    "        snap_idx = get_snapshot_index(f)\n",
    "        if snap_idx is None:\n",
    "            continue\n",
    "\n",
    "        # Parse the M33 snapshot\n",
    "        t_m33, count_m33, data_m33 = parse_galaxy_file(f)\n",
    "        (ptype, mass, x, y, z, vx, vy, vz) = data_m33\n",
    "\n",
    "        # Center M33 by subtracting the COM\n",
    "        xcom, ycom, zcom = center_of_mass(x, y, z, mass)\n",
    "        x_shift = x - xcom\n",
    "        y_shift = y - ycom\n",
    "        z_shift = z - zcom\n",
    "\n",
    "        vx_shift = vx\n",
    "        vy_shift = vy\n",
    "        vz_shift = vz\n",
    "\n",
    "        # If requested, filter down to only disk particles (type==disk_type)\n",
    "        if filter_disk:\n",
    "            disk_mask = (ptype == disk_type)\n",
    "            x_shift = x_shift[disk_mask]\n",
    "            y_shift = y_shift[disk_mask]\n",
    "            z_shift = z_shift[disk_mask]\n",
    "            vx_shift = vx_shift[disk_mask]\n",
    "            vy_shift = vy_shift[disk_mask]\n",
    "            vz_shift = vz_shift[disk_mask]\n",
    "\n",
    "        # If too few particles remain, skip plotting\n",
    "        if len(x_shift) < 10:\n",
    "            logging.warning(\n",
    "                f\"Snapshot {snap_idx}: only {len(x_shift)} disk particles, skipping figure.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Combine positions & velocities for disk rotation\n",
    "        pos_arr = np.column_stack((x_shift, y_shift, z_shift))\n",
    "        vel_arr = np.column_stack((vx_shift, vy_shift, vz_shift))\n",
    "\n",
    "        # Rotate to align the disk angular momentum with +z\n",
    "        pos_rot, vel_rot = rotate_frame(pos_arr, vel_arr)\n",
    "        x_rot = pos_rot[:, 0]\n",
    "        y_rot = pos_rot[:, 1]\n",
    "        z_rot = pos_rot[:, 2]\n",
    "\n",
    "        # Create a single figure with 1 row and 2 columns\n",
    "        # Size 12 wide, 6 high\n",
    "        fig, (ax_face, ax_edge) = plt.subplots(\n",
    "            nrows=1, ncols=2, figsize=(12, 6)\n",
    "        )\n",
    "\n",
    "        nbins = 150\n",
    "\n",
    "        # Left subplot: Face-On (x_rot vs. y_rot)\n",
    "        h_face = ax_face.hist2d(x_rot, y_rot, bins=nbins, cmap='magma')\n",
    "        ax_face.set_xlabel(\"x (kpc)\")\n",
    "        ax_face.set_ylabel(\"y (kpc)\")\n",
    "        ax_face.set_title(f\"M33_{snap_idx:03d} Face-On (t={t_m33:.2f} Gyr)\")\n",
    "        ax_face.set_aspect('equal', 'box')\n",
    "        fig.colorbar(h_face[3], ax=ax_face, label=\"Counts\")\n",
    "\n",
    "        # Right subplot: Edge-On (x_rot vs. z_rot)\n",
    "        h_edge = ax_edge.hist2d(x_rot, z_rot, bins=nbins, cmap='magma')\n",
    "        ax_edge.set_xlabel(\"x (kpc)\")\n",
    "        ax_edge.set_ylabel(\"z (kpc)\")\n",
    "        ax_edge.set_title(\"Edge-On View\")\n",
    "        ax_edge.set_aspect('equal', 'box')\n",
    "        fig.colorbar(h_edge[3], ax=ax_edge, label=\"Counts\")\n",
    "\n",
    "        # Save to disk\n",
    "        os.makedirs(PLOTS_DIRECTORY, exist_ok=True)\n",
    "        outfig = os.path.join(PLOTS_DIRECTORY, f\"M33_morph_{snap_idx:03d}.png\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outfig, dpi=150)\n",
    "        plt.close(fig)\n",
    "\n",
    "        logging.info(\n",
    "            f\"Snapshot {snap_idx}: combined face-on & edge-on figure saved -> {outfig}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "generate_morphology_plots_all_snaps_side_by_side(filter_disk=True, disk_type=2)\n",
    "print(\"Cell 5.1.2 updated: side-by-side face-on & edge-on morphological plots for each snapshot, 12x6 figure size.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de434ef-ef8e-4f68-b4fa-6164b877f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# ---------------------------------------------------------------\n",
    "# Cell 5.2.1 — \"Spiral Arm Identification & Pitch Angle Function\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import logging\n",
    "\n",
    "def log_spiral_func(R, theta0, m):\n",
    "    \"\"\"\n",
    "    Defines a logarithmic spiral in polar form:\n",
    "        theta(R) = theta0 + m * ln(R)\n",
    "\n",
    "    We'll fit the data (R, theta) to this function \n",
    "    to find the best (theta0, m).\n",
    "\n",
    "    Then the pitch angle p is given by:\n",
    "        p = arctan(1/m)\n",
    "    if we adopt the form  theta = c + m ln(R).\n",
    "    \"\"\"\n",
    "    return theta0 + m * np.log(R)\n",
    "\n",
    "\n",
    "def measure_spiral_pitch_angle(pos_rot, rmin=1.0, rmax=15.0):\n",
    "    \"\"\"\n",
    "    Attempts to measure the spiral pitch angle of a disk \n",
    "    by fitting a log-spiral:  theta = c + m ln(R).\n",
    "\n",
    "    Steps:\n",
    "      1) Convert (x_rot,y_rot) -> (R,theta) in plane\n",
    "      2) Restrict data to rmin < R < rmax\n",
    "      3) Use curve_fit to find (theta0, m)\n",
    "      4) pitch_angle = arctan(1/m)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pitch_angle : float\n",
    "        pitch angle in degrees\n",
    "    theta0_best : float\n",
    "        intercept in the log-spiral fit (radians)\n",
    "    m_best : float\n",
    "        slope in the log-spiral fit\n",
    "    \"\"\"\n",
    "    x = pos_rot[:,0]\n",
    "    y = pos_rot[:,1]\n",
    "\n",
    "    R = np.sqrt(x**2 + y**2)\n",
    "    # angle range is -pi..pi from arctan2\n",
    "    theta = np.arctan2(y, x)\n",
    "\n",
    "    # filter radius\n",
    "    mask = (R > rmin) & (R < rmax)\n",
    "    R_cut = R[mask]\n",
    "    theta_cut = theta[mask]\n",
    "\n",
    "    # If no data, return NaN\n",
    "    if len(R_cut) < 2:\n",
    "        logging.warning(\"measure_spiral_pitch_angle: Not enough points in [rmin,rmax]. Returning NaN.\")\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "    # We'll attempt to unwrap theta so it's monotonic-ish for the fit.\n",
    "    # But for multiple arms, or a large scatter, a single log-spiral might not capture it well.\n",
    "    # For a naive approach, let's just shift negative thetas to positive so we get 0..2pi.\n",
    "    # A more robust method might do a partial unwrapping in segments.\n",
    "    # We'll do a simple approach:\n",
    "    theta_positive = np.where(theta_cut<0, theta_cut+2*np.pi, theta_cut)\n",
    "\n",
    "    # initial guess\n",
    "    guess_theta0 = 0.0\n",
    "    guess_m      = 1.0\n",
    "\n",
    "    # define the function in terms of R\n",
    "    def log_spiral_fit(R, theta0, m):\n",
    "        return theta0 + m * np.log(R)\n",
    "\n",
    "    # curve_fit\n",
    "    try:\n",
    "        popt, pcov = curve_fit(log_spiral_fit, R_cut, theta_positive,\n",
    "                               p0=[guess_theta0, guess_m],\n",
    "                               maxfev=2000)\n",
    "        theta0_best, m_best = popt\n",
    "    except RuntimeError:\n",
    "        logging.warning(\"measure_spiral_pitch_angle: curve_fit did not converge.\")\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "    # pitch angle in degrees\n",
    "    # form:  theta(R) = c + m ln(R) => R = exp((theta-c)/m)\n",
    "    # slope is dtheta/d(lnR) = m => pitch angle p = arctan(1/m).\n",
    "    pitch_angle_radians = np.arctan(1.0/m_best)\n",
    "    pitch_angle_degs = np.degrees(pitch_angle_radians)\n",
    "\n",
    "    return pitch_angle_degs, theta0_best, m_best\n",
    "\n",
    "print(\"Cell 5.2.1 completed: measure_spiral_pitch_angle() function defined.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a86910d-3998-43bf-9970-c28813f57686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# ---------------------------------------------------------------\n",
    "# Cell 5.2.2 — \"Spiral Arm Timeseries: Pitch Angle vs. Time\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_spiral_pitch_timeseries(rmin=1.0, rmax=15.0, filter_disk=True, disk_type=2,\n",
    "                                    save_results=SAVE_INTERMEDIATE_RESULTS):\n",
    "    \"\"\"\n",
    "    For each M33 snapshot:\n",
    "      1) parse, center, optionally filter disk\n",
    "      2) rotate to face-on\n",
    "      3) measure pitch angle in [rmin, rmax]\n",
    "      4) store (time, pitch_angle)\n",
    "    Returns arrays => times_spiral, pitch_arr\n",
    "\n",
    "    If save_results=True, also saves 'spiral_pitch_vs_time.npy' in results folder.\n",
    "    \"\"\"\n",
    "    import glob, os\n",
    "    m33_files = sorted(glob.glob(f\"{M33_DIRECTORY}M33_*.txt\"))\n",
    "\n",
    "    times_list = []\n",
    "    pitch_list = []\n",
    "\n",
    "    for f in m33_files:\n",
    "        snap_idx = get_snapshot_index(f)\n",
    "        if snap_idx is None:\n",
    "            continue\n",
    "\n",
    "        # parse\n",
    "        t_m33, count_m33, data_m33 = parse_galaxy_file(f)\n",
    "        (ptype, mass, x, y, z, vx, vy, vz) = data_m33\n",
    "\n",
    "        # shift M33\n",
    "        xcom, ycom, zcom = center_of_mass(x, y, z, mass)\n",
    "        x_shift = x - xcom\n",
    "        y_shift = y - ycom\n",
    "        z_shift = z - zcom\n",
    "\n",
    "        vx_shift = vx\n",
    "        vy_shift = vy\n",
    "        vz_shift = vz\n",
    "\n",
    "        # optionally filter for disk\n",
    "        if filter_disk:\n",
    "            disk_mask = (ptype == disk_type)\n",
    "            x_shift = x_shift[disk_mask]\n",
    "            y_shift = y_shift[disk_mask]\n",
    "            z_shift = z_shift[disk_mask]\n",
    "            vx_shift = vx_shift[disk_mask]\n",
    "            vy_shift = vy_shift[disk_mask]\n",
    "            vz_shift = vz_shift[disk_mask]\n",
    "\n",
    "        if len(x_shift) < 50:\n",
    "            # not enough disk points to measure arms\n",
    "            pitch_list.append(np.nan)\n",
    "            times_list.append(t_m33)\n",
    "            logging.info(f\"Snapshot {snap_idx}: <50 disk particles, skipping spiral measurement.\")\n",
    "            continue\n",
    "\n",
    "        # rotate\n",
    "        pos_arr = np.column_stack((x_shift, y_shift, z_shift))\n",
    "        vel_arr = np.column_stack((vx_shift, vy_shift, vz_shift))\n",
    "        pos_rot, vel_rot = rotate_frame(pos_arr, vel_arr)\n",
    "        # measure pitch angle\n",
    "        pitch_angle, theta0_best, m_best = measure_spiral_pitch_angle(pos_rot, rmin=rmin, rmax=rmax)\n",
    "\n",
    "        pitch_list.append(pitch_angle)\n",
    "        times_list.append(t_m33)\n",
    "\n",
    "        logging.info(f\"Snapshot {snap_idx}: time={t_m33:.2f} => pitch={pitch_angle:.2f} deg\")\n",
    "\n",
    "    times_spiral = np.array(times_list)\n",
    "    pitch_arr    = np.array(pitch_list)\n",
    "\n",
    "    # sort by time\n",
    "    idx = np.argsort(times_spiral)\n",
    "    times_spiral = times_spiral[idx]\n",
    "    pitch_arr    = pitch_arr[idx]\n",
    "\n",
    "    # optionally save\n",
    "    if save_results and len(times_spiral)>0:\n",
    "        os.makedirs(RESULTS_DIRECTORY, exist_ok=True)\n",
    "        outfile = os.path.join(RESULTS_DIRECTORY, \"spiral_pitch_vs_time.npy\")\n",
    "        np.save(outfile, np.column_stack((times_spiral, pitch_arr)))\n",
    "        logging.info(f\"Spiral pitch results saved to {outfile}\")\n",
    "\n",
    "    return times_spiral, pitch_arr\n",
    "\n",
    "\n",
    "def plot_spiral_pitch_timeseries(times_spiral, pitch_arr,\n",
    "                                 outfig=\"spiral_pitch_vs_time.png\"):\n",
    "    \"\"\"\n",
    "    Plots pitch angle vs. time. If pitch_arr has many NaNs,\n",
    "    we'll just show them as gaps or drop them.\n",
    "\n",
    "    times_spiral : array\n",
    "    pitch_arr    : array\n",
    "    \"\"\"\n",
    "    if len(times_spiral)==0:\n",
    "        print(\"No spiral pitch data to plot.\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7,5))\n",
    "    ax.plot(times_spiral, pitch_arr, '-', color='red', label='Spiral Pitch Angle')\n",
    "\n",
    "    ax.set_xlabel(\"Time (Gyr)\")\n",
    "    ax.set_ylabel(\"Pitch Angle (deg)\")\n",
    "    ax.set_title(\"Spiral Pitch Angle vs. Time\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "    # summary\n",
    "    valid_pitch = pitch_arr[~np.isnan(pitch_arr)]\n",
    "    if len(valid_pitch)>1:\n",
    "        initial = valid_pitch[0]\n",
    "        final   = valid_pitch[-1]\n",
    "        # difference or something\n",
    "        diff = final-initial\n",
    "        msg = f\"From {initial:.1f} deg to {final:.1f} deg (delta={diff:.1f})\"\n",
    "        ax.text(0.05, 0.85, msg, transform=ax.transAxes,\n",
    "                fontsize=10, bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "    if outfig:\n",
    "        os.makedirs(PLOTS_DIRECTORY, exist_ok=True)\n",
    "        outfile = os.path.join(PLOTS_DIRECTORY, outfig)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outfile, dpi=150)\n",
    "        print(f\"Spiral pitch timeseries plot saved to {outfile}\")\n",
    "\n",
    "    plt.show()\n",
    "    print(\"\\nDone: pitch angle timeseries plot.\\n\")\n",
    "\n",
    "\n",
    "# We'll run the timeseries measurement and plot\n",
    "times_spiral, pitch_arr = compute_spiral_pitch_timeseries(rmin=1.0, rmax=15.0, filter_disk=True)\n",
    "plot_spiral_pitch_timeseries(times_spiral, pitch_arr)\n",
    "\n",
    "print(\"Cell 5.2.2 completed: spiral arm timeseries measurement & plot generated.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1fd274-a238-4b71-a50c-85940b47ce7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5.2.1 and 5.2.2\n",
    "# --------------------------------------------------------------------------------\n",
    "# COMBINED CELL: Spiral Arm Pitch Angle Computation & Timeseries\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from scipy.optimize import curve_fit\n",
    "import os\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# 1) Spiral-fitting function\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "def log_spiral_func(R, theta0, m):\n",
    "    \"\"\"\n",
    "    Defines a logarithmic spiral in polar form:\n",
    "        theta(R) = theta0 + m * ln(R)\n",
    "\n",
    "    We'll fit (R, theta) data to find best (theta0, m).\n",
    "    Then pitch angle p = arctan(1/m) for the form theta = c + m ln(R).\n",
    "    \"\"\"\n",
    "    return theta0 + m * np.log(R)\n",
    "\n",
    "def measure_spiral_pitch_angle(pos_rot, rmin=1.0, rmax=15.0, \n",
    "                               min_points_for_fit=20):\n",
    "    \"\"\"\n",
    "    Attempts to measure the spiral pitch angle of a disk \n",
    "    by fitting a log-spiral:  theta = c + m ln(R).\n",
    "\n",
    "    Steps:\n",
    "      1) Convert (x_rot, y_rot) -> (R, theta)\n",
    "      2) Restrict data to rmin < R < rmax\n",
    "      3) Use curve_fit(...) to find (theta0, m)\n",
    "      4) pitch_angle = arctan(1/m) in degrees\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pos_rot : np.ndarray shape (N,3)\n",
    "        Rotated star/disk positions (x,y,z). We only use x,y for the spiral fit.\n",
    "    rmin, rmax : float\n",
    "        The radial bounds (kpc) within which we attempt to find a spiral.\n",
    "        If the disk is smaller or bigger, many points may be outside.\n",
    "    min_points_for_fit : int\n",
    "        The minimum number of points required to attempt a log-spiral fit.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pitch_angle_degs : float\n",
    "        Measured pitch angle in degrees (NaN if not enough data).\n",
    "    theta0_best : float\n",
    "        The best-fit intercept (in radians).\n",
    "    m_best : float\n",
    "        The best-fit slope in the log-spiral eqn.\n",
    "    \"\"\"\n",
    "    # Unpack x,y from the rotated positions\n",
    "    x = pos_rot[:,0]\n",
    "    y = pos_rot[:,1]\n",
    "\n",
    "    # Convert to polar coords\n",
    "    R = np.sqrt(x**2 + y**2)          # radius\n",
    "    theta = np.arctan2(y, x)          # angle in -pi..pi\n",
    "\n",
    "    # Filter based on radial range\n",
    "    mask = (R > rmin) & (R < rmax)\n",
    "    R_cut = R[mask]\n",
    "    theta_cut = theta[mask]\n",
    "\n",
    "    # If not enough data\n",
    "    if len(R_cut) < min_points_for_fit:\n",
    "        logging.warning(f\"measure_spiral_pitch_angle: Only {len(R_cut)} points \"\n",
    "                        f\"in [r={rmin},{rmax}], need >= {min_points_for_fit}. Returning NaN.\")\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "    # Simple \"unwrapping\": shift negative angles to 0..2pi range\n",
    "    # (Better methods can do partial unwrapping or handle multiple arms.)\n",
    "    theta_positive = np.where(theta_cut < 0, theta_cut + 2*np.pi, theta_cut)\n",
    "\n",
    "    # We'll define a local function for the fit\n",
    "    def log_spiral_fit(R_array, theta0, m):\n",
    "        return theta0 + m * np.log(R_array)\n",
    "\n",
    "    # Initial guesses\n",
    "    guess_theta0 = 0.0\n",
    "    guess_m      = 1.0\n",
    "\n",
    "    try:\n",
    "        popt, pcov = curve_fit(\n",
    "            log_spiral_fit, \n",
    "            R_cut, \n",
    "            theta_positive,\n",
    "            p0=[guess_theta0, guess_m],\n",
    "            maxfev=2000\n",
    "        )\n",
    "        theta0_best, m_best = popt\n",
    "    except RuntimeError:\n",
    "        logging.warning(\"measure_spiral_pitch_angle: curve_fit did not converge. Returning NaN.\")\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "    # pitch angle => p = arctan(1/m) in radians, then convert to degrees\n",
    "    pitch_angle_radians = np.arctan(1.0 / m_best)\n",
    "    pitch_angle_degs    = np.degrees(pitch_angle_radians)\n",
    "\n",
    "    return pitch_angle_degs, theta0_best, m_best\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# 2) Timeseries function\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "def compute_spiral_pitch_timeseries(\n",
    "    rmin=1.0, \n",
    "    rmax=15.0, \n",
    "    filter_disk=True, \n",
    "    disk_type=2,\n",
    "    min_points_for_fit=20,       # you can lower this if you want to fit with fewer points\n",
    "    save_results=SAVE_INTERMEDIATE_RESULTS\n",
    "):\n",
    "    \"\"\"\n",
    "    Loops over M33 snapshots to measure pitch angle at each time.\n",
    "\n",
    "    Steps:\n",
    "      1) parse data\n",
    "      2) center M33\n",
    "      3) optionally filter for disk only\n",
    "      4) rotate to face-on (rotate_frame) \n",
    "      5) measure pitch angle in [rmin, rmax] with measure_spiral_pitch_angle()\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rmin, rmax : float\n",
    "        radial bounds for the spiral-fitting (kpc).\n",
    "    filter_disk : bool\n",
    "        If True, only pick type=disk_type particles.\n",
    "    disk_type : int\n",
    "        Particle type for the disk (commonly 2).\n",
    "    min_points_for_fit : int\n",
    "        min # of points to do the log-spiral curve_fit. \n",
    "        If fewer, returns NaN for that snapshot.\n",
    "    save_results : bool\n",
    "        If True, saves the final (time, pitch) to 'spiral_pitch_vs_time.npy'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    times_spiral : np.ndarray\n",
    "    pitch_arr    : np.ndarray\n",
    "        Both sorted by time ascending.\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    m33_files = sorted(glob.glob(f\"{M33_DIRECTORY}M33_*.txt\"))\n",
    "\n",
    "    times_list  = []\n",
    "    pitch_list  = []\n",
    "\n",
    "    for f in m33_files:\n",
    "        snap_idx = get_snapshot_index(f)\n",
    "        if snap_idx is None:\n",
    "            continue\n",
    "\n",
    "        # parse\n",
    "        t_m33, count_m33, data_m33 = parse_galaxy_file(f)\n",
    "        (ptype, mass, x, y, z, vx, vy, vz) = data_m33\n",
    "\n",
    "        # shift M33 by COM\n",
    "        xcom, ycom, zcom = center_of_mass(x, y, z, mass)\n",
    "        x_shift = x - xcom\n",
    "        y_shift = y - ycom\n",
    "        z_shift = z - zcom\n",
    "        vx_shift = vx\n",
    "        vy_shift = vy\n",
    "        vz_shift = vz\n",
    "\n",
    "        # optionally filter to disk only\n",
    "        if filter_disk:\n",
    "            disk_mask = (ptype == disk_type)\n",
    "            x_shift = x_shift[disk_mask]\n",
    "            y_shift = y_shift[disk_mask]\n",
    "            z_shift = z_shift[disk_mask]\n",
    "            vx_shift = vx_shift[disk_mask]\n",
    "            vy_shift = vy_shift[disk_mask]\n",
    "            vz_shift = vz_shift[disk_mask]\n",
    "\n",
    "        # if very few disk points, skip\n",
    "        if len(x_shift) < 50:\n",
    "            pitch_list.append(np.nan)\n",
    "            times_list.append(t_m33)\n",
    "            logging.info(f\"Snapshot {snap_idx}: <50 disk particles => skip spiral measurement.\")\n",
    "            continue\n",
    "\n",
    "        # rotate to face-on\n",
    "        pos_arr = np.column_stack((x_shift, y_shift, z_shift))\n",
    "        vel_arr = np.column_stack((vx_shift, vy_shift, vz_shift))\n",
    "        pos_rot, vel_rot = rotate_frame(pos_arr, vel_arr)\n",
    "\n",
    "        # measure pitch angle\n",
    "        pitch_angle, theta0_best, m_best = measure_spiral_pitch_angle(\n",
    "            pos_rot, \n",
    "            rmin=rmin, \n",
    "            rmax=rmax,\n",
    "            min_points_for_fit=min_points_for_fit\n",
    "        )\n",
    "\n",
    "        pitch_list.append(pitch_angle)\n",
    "        times_list.append(t_m33)\n",
    "\n",
    "        logging.info(f\"Snapshot {snap_idx:03d}: time={t_m33:.2f}, pitch={pitch_angle:.2f} deg\")\n",
    "\n",
    "    # convert to arrays and sort by time\n",
    "    times_spiral = np.array(times_list)\n",
    "    pitch_arr    = np.array(pitch_list)\n",
    "    idx = np.argsort(times_spiral)\n",
    "    times_spiral = times_spiral[idx]\n",
    "    pitch_arr    = pitch_arr[idx]\n",
    "\n",
    "    # optionally save\n",
    "    if save_results and len(times_spiral)>0:\n",
    "        os.makedirs(RESULTS_DIRECTORY, exist_ok=True)\n",
    "        outfile = os.path.join(RESULTS_DIRECTORY, \"spiral_pitch_vs_time.npy\")\n",
    "        np.save(outfile, np.column_stack((times_spiral, pitch_arr)))\n",
    "        logging.info(f\"Spiral pitch results saved to {outfile}\")\n",
    "\n",
    "    return times_spiral, pitch_arr\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# 3) Plot function\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "def plot_spiral_pitch_timeseries(times_spiral, pitch_arr, outfig=\"spiral_pitch_vs_time.png\"):\n",
    "    \"\"\"\n",
    "    Plots pitch angle vs. time, ignoring NaNs. \n",
    "    If there's a large gap in times, that often indicates\n",
    "    many snapshots returned NaN (the disk wasn't in the chosen radial range).\n",
    "\n",
    "    times_spiral : np.ndarray\n",
    "    pitch_arr    : np.ndarray\n",
    "        (NaNs for those with insufficient data)\n",
    "    outfig : str\n",
    "        filename to save, or None to skip saving\n",
    "    \"\"\"\n",
    "    if len(times_spiral) == 0:\n",
    "        print(\"No spiral pitch data to plot at all.\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,5))\n",
    "    ax.plot(times_spiral, pitch_arr, '-', color='red', label='Spiral Pitch Angle')\n",
    "\n",
    "    ax.set_xlabel(\"Time (Gyr)\")\n",
    "    ax.set_ylabel(\"Pitch Angle (deg)\")\n",
    "    ax.set_title(\"Spiral Pitch Angle vs. Time\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "    # Summarize initial & final pitch angles if we have multiple valid points\n",
    "    valid_pitch = pitch_arr[~np.isnan(pitch_arr)]\n",
    "    if len(valid_pitch) > 1:\n",
    "        initial = valid_pitch[0]\n",
    "        final   = valid_pitch[-1]\n",
    "        diff = final - initial\n",
    "        msg = f\"From {initial:.1f} deg to {final:.1f} deg (delta={diff:.1f})\"\n",
    "        ax.text(0.05, 0.85, msg, transform=ax.transAxes,\n",
    "                fontsize=10, bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "    if outfig:\n",
    "        os.makedirs(PLOTS_DIRECTORY, exist_ok=True)\n",
    "        outfile = os.path.join(PLOTS_DIRECTORY, outfig)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outfile, dpi=150)\n",
    "        print(f\"Spiral pitch timeseries plot saved to {outfile}\")\n",
    "\n",
    "    plt.show()\n",
    "    print(\"\\nDone: pitch angle timeseries plot.\\n\")\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# 4) Example usage in a single code cell\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# We'll run the timeseries measurement & plotting with default rmin=1.0, rmax=15.0\n",
    "# To experiment, adjust the function call below:\n",
    "'''\n",
    "times_spiral, pitch_arr = compute_spiral_pitch_timeseries(\n",
    "    rmin=1.0,     # <-- Try lowering to 0.5 or 0.1 if your disk shrinks below 1 kpc\n",
    "    rmax=15.0,    # <-- Try raising to 20 if disk extends further at some epochs\n",
    "    filter_disk=True, \n",
    "    disk_type=2,\n",
    "    min_points_for_fit=20  # <-- Lower to 10 if you want a fit w/ fewer points\n",
    ")\n",
    "\n",
    "plot_spiral_pitch_timeseries(times_spiral, pitch_arr, outfig=\"spiral_pitch_vs_time.png\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "#  BELOW are some \"alternate lines\" you might try by commenting/uncommenting:\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "times_spiral, pitch_arr = compute_spiral_pitch_timeseries(\n",
    "    rmin=0.5,   # smaller rmin to catch smaller disk radius\n",
    "    rmax=25.0,  # bigger rmax\n",
    "    filter_disk=True,\n",
    "    disk_type=2,\n",
    "    min_points_for_fit=10  # accept fewer points\n",
    ")\n",
    "plot_spiral_pitch_timeseries(times_spiral, pitch_arr, outfig=\"spiral_pitch_vs_time_altA.png\")\n",
    "'''\n",
    "\n",
    "times_spiral, pitch_arr = compute_spiral_pitch_timeseries(\n",
    "    rmin=1.0,\n",
    "    rmax=15.0,\n",
    "    filter_disk=False,  # see if using ALL stellar particles helps\n",
    "    disk_type=2,\n",
    "    min_points_for_fit=2\n",
    ")\n",
    "plot_spiral_pitch_timeseries(times_spiral, pitch_arr, outfig=\"spiral_pitch_vs_time_altB.png\")\n",
    "\n",
    "print(\"\\n<<< Combined Spiral Pitch Angle Code Completed >>>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb4f57-2578-4ea5-a657-6809caa45ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755b481-0aa6-487d-9338-3bd9b2049c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c85ec1f-a69a-4bee-9ff6-c6460fabf761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 5.3.1 — \"Warp Computation vs. Radius\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "def plane_normal_svd(x, y, z):\n",
    "    \"\"\"\n",
    "    Computes the best-fit plane normal using SVD on the (x,y,z) points.\n",
    "    We find the mean, shift, then do an SVD. The last singular vector\n",
    "    is the plane normal.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    normal : np.ndarray of shape (3,)\n",
    "        Unit normal vector to the best-fit plane.\n",
    "    \"\"\"\n",
    "    coords = np.column_stack((x, y, z))\n",
    "    centroid = coords.mean(axis=0)\n",
    "    coords_centered = coords - centroid\n",
    "    if coords_centered.shape[0] < 3:\n",
    "        return np.array([0,0,1], dtype=float)  # fallback\n",
    "\n",
    "    # SVD\n",
    "    u, s, vh = np.linalg.svd(coords_centered, full_matrices=False)\n",
    "    # The last column of vh is the direction with smallest variance => plane normal\n",
    "    normal = vh[-1, :]\n",
    "    norm_mag = np.linalg.norm(normal)\n",
    "    if norm_mag < 1e-10:\n",
    "        return np.array([0,0,1], dtype=float)\n",
    "    return normal / norm_mag\n",
    "\n",
    "\n",
    "def measure_warp_angles(pos_rot, nbins=5, rmax=30.0):\n",
    "    \"\"\"\n",
    "    Subdivide radius in nbins from [0, rmax], measure the local plane normal \n",
    "    in each annulus, compare to the global disk normal => warp angle at that radius.\n",
    "\n",
    "    Steps:\n",
    "      1) pos_rot is shape (N,3), presumably face-on or some orientation. \n",
    "         But here we'll do a generic approach:\n",
    "         We'll define 'global normal' from the entire disk (plane_normal_svd).\n",
    "      2) Subdivide R = sqrt(x^2+y^2) into nbins up to rmax. \n",
    "      3) For each annulus, compute the local normal via plane_normal_svd() \n",
    "         and measure the angle wrt global normal.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    r_mid : np.ndarray\n",
    "        radial midpoints for each annulus\n",
    "    warp_angle : np.ndarray\n",
    "        angle in degrees of local plane wrt global plane\n",
    "    \"\"\"\n",
    "    x = pos_rot[:,0]\n",
    "    y = pos_rot[:,1]\n",
    "    z = pos_rot[:,2]\n",
    "    R = np.sqrt(x**2 + y**2)\n",
    "\n",
    "    # \"global\" normal from entire disk\n",
    "    global_normal = plane_normal_svd(x, y, z)\n",
    "\n",
    "    # define radial bins\n",
    "    edges = np.linspace(0, rmax, nbins+1)\n",
    "    r_mid = 0.5*(edges[:-1] + edges[1:])\n",
    "    warp_angle = np.zeros(nbins) + np.nan\n",
    "\n",
    "    for i in range(nbins):\n",
    "        r_in  = edges[i]\n",
    "        r_out = edges[i+1]\n",
    "        mask  = (R >= r_in) & (R < r_out)\n",
    "        x_sub = x[mask]\n",
    "        y_sub = y[mask]\n",
    "        z_sub = z[mask]\n",
    "        if len(x_sub) < 10:\n",
    "            # not enough points\n",
    "            continue\n",
    "        local_normal = plane_normal_svd(x_sub, y_sub, z_sub)\n",
    "        # angle wrt global normal\n",
    "        dot_val = np.dot(local_normal, global_normal)\n",
    "        dot_val = max(min(dot_val, 1.0), -1.0)  # clamp\n",
    "        angle_rad = np.arccos(dot_val)\n",
    "        angle_deg = np.degrees(angle_rad)\n",
    "        warp_angle[i] = angle_deg\n",
    "\n",
    "    return r_mid, warp_angle\n",
    "\n",
    "print(\"Cell 5.3.1 completed: measure_warp_angles() function defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac4b2b0-4c0f-4d45-bd5d-de1117a8cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 5.3.2 — \"Scale Height Computation\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "def measure_scale_height(pos_rot, nbins=5, rmax=30.0):\n",
    "    \"\"\"\n",
    "    For each radial annulus, measure the vertical distribution (z) => scale height.\n",
    "\n",
    "    We'll define scale height as the std dev in z for that annulus.\n",
    "    (One could do FWHM, or half-mass thickness, etc. but let's do std dev.)\n",
    "\n",
    "    pos_rot : np.ndarray, shape (N,3)\n",
    "        Rotated coords (face-on). So z is 'vertical'.\n",
    "\n",
    "    nbins : int\n",
    "    rmax : float\n",
    "        radial range in kpc\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    r_mid : np.ndarray\n",
    "        radial midpoints\n",
    "    height_arr : np.ndarray\n",
    "        scale height in kpc (std dev of z)\n",
    "    \"\"\"\n",
    "    x = pos_rot[:,0]\n",
    "    y = pos_rot[:,1]\n",
    "    z = pos_rot[:,2]\n",
    "    R = np.sqrt(x**2 + y**2)\n",
    "\n",
    "    edges = np.linspace(0, rmax, nbins+1)\n",
    "    r_mid = 0.5*(edges[:-1] + edges[1:])\n",
    "    height_arr = np.zeros(nbins) + np.nan\n",
    "\n",
    "    for i in range(nbins):\n",
    "        r_in  = edges[i]\n",
    "        r_out = edges[i+1]\n",
    "        mask  = (R >= r_in) & (R < r_out)\n",
    "        z_sub = z[mask]\n",
    "        if len(z_sub) < 10:\n",
    "            continue\n",
    "        # std dev\n",
    "        z_std = np.std(z_sub)\n",
    "        height_arr[i] = z_std\n",
    "\n",
    "    return r_mid, height_arr\n",
    "\n",
    "print(\"Cell 5.3.2 completed: measure_scale_height() function defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd8c7a9-cb4b-43f8-a550-b75751cd345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 5.3.3 — \"Warp & Height Plots & Discussion\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def demo_warp_scale_for_snapshot(snapshot_index=0, nbins=5, rmax=30.0, filter_disk=True, disk_type=2):\n",
    "    \"\"\"\n",
    "    Demonstrate warp & scale height computations for a single snapshot. \n",
    "    We'll parse M33, center, rotate, measure warp angles & scale height,\n",
    "    then plot them.\n",
    "\n",
    "    Outputs a 2-panel figure:\n",
    "      Panel 1: warp angle vs. radius\n",
    "      Panel 2: scale height vs. radius\n",
    "    \"\"\"\n",
    "    file_m33 = f\"{M33_DIRECTORY}M33_{snapshot_index:03d}.txt\"\n",
    "    t_m33, count_m33, data_m33 = parse_galaxy_file(file_m33)\n",
    "    (ptype, mass, x, y, z, vx, vy, vz) = data_m33\n",
    "\n",
    "    # shift\n",
    "    xcom, ycom, zcom = center_of_mass(x, y, z, mass)\n",
    "    x_shift = x - xcom\n",
    "    y_shift = y - ycom\n",
    "    z_shift = z - zcom\n",
    "\n",
    "    vx_shift = vx\n",
    "    vy_shift = vy\n",
    "    vz_shift = vz\n",
    "\n",
    "    if filter_disk:\n",
    "        disk_mask = (ptype == disk_type)\n",
    "        x_shift = x_shift[disk_mask]\n",
    "        y_shift = y_shift[disk_mask]\n",
    "        z_shift = z_shift[disk_mask]\n",
    "        vx_shift = vx_shift[disk_mask]\n",
    "        vy_shift = vy_shift[disk_mask]\n",
    "        vz_shift = vz_shift[disk_mask]\n",
    "\n",
    "    if len(x_shift) < 50:\n",
    "        print(f\"Snapshot {snapshot_index}: <50 disk particles, warp/height might be meaningless.\")\n",
    "        return\n",
    "\n",
    "    pos_arr = np.column_stack((x_shift, y_shift, z_shift))\n",
    "    vel_arr = np.column_stack((vx_shift, vy_shift, vz_shift))\n",
    "\n",
    "    pos_rot, vel_rot = rotate_frame(pos_arr, vel_arr)\n",
    "\n",
    "    # measure warp\n",
    "    r_warp, warp_angle = measure_warp_angles(pos_rot, nbins=nbins, rmax=rmax)\n",
    "\n",
    "    # measure scale height\n",
    "    r_height, height_arr = measure_scale_height(pos_rot, nbins=nbins, rmax=rmax)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "    ax1.plot(r_warp, warp_angle, 'o-', color='blue')\n",
    "    ax1.set_xlabel(\"Radius (kpc)\")\n",
    "    ax1.set_ylabel(\"Warp Angle (deg)\")\n",
    "    ax1.set_title(f\"M33_{snapshot_index:03d} Warp (t={t_m33:.2f} Gyr)\")\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2.plot(r_height, height_arr, 'o-', color='green')\n",
    "    ax2.set_xlabel(\"Radius (kpc)\")\n",
    "    ax2.set_ylabel(\"Scale Height (kpc)\")\n",
    "    ax2.set_title(\"Scale Height vs. Radius\")\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(PLOTS_DIRECTORY, exist_ok=True)\n",
    "    outfig = os.path.join(PLOTS_DIRECTORY, f\"M33_{snapshot_index:03d}_WarpScaleDemo.png\")\n",
    "    plt.savefig(outfig, dpi=150)\n",
    "    print(f\"Warp & Scale Height demo for snapshot {snapshot_index} saved to {outfig}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def multi_snapshot_warp_scale(n_snaps=3, nbins=5, rmax=30.0):\n",
    "    \"\"\"\n",
    "    Example function to pick ~3 snapshots across the entire run \n",
    "    (e.g., early, middle, late) and overlay their warp & scale height curves \n",
    "    on a single figure, so we can see changes over time.\n",
    "\n",
    "    For real usage, one might loop or do a more robust approach.\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    import math\n",
    "\n",
    "    m33_files = sorted(glob.glob(f\"{M33_DIRECTORY}M33_*.txt\"))\n",
    "    if len(m33_files) < n_snaps:\n",
    "        print(f\"Not enough snapshots to pick {n_snaps} distinct times.\")\n",
    "        return\n",
    "\n",
    "    # pick snapshots at equal intervals\n",
    "    step = max(1, len(m33_files)//n_snaps)\n",
    "    chosen_files = m33_files[::step][:n_snaps]\n",
    "\n",
    "    figW, axW = plt.subplots(figsize=(6,5))\n",
    "    figH, axH = plt.subplots(figsize=(6,5))\n",
    "\n",
    "    for i, f in enumerate(chosen_files):\n",
    "        snap_idx = get_snapshot_index(f)\n",
    "        t_val, count_m33, data_m33 = parse_galaxy_file(f)\n",
    "        (ptype, mass, x, y, z, vx, vy, vz) = data_m33\n",
    "        xcom, ycom, zcom = center_of_mass(x, y, z, mass)\n",
    "        pos_arr = np.column_stack((x-xcom, y-ycom, z-zcom))\n",
    "        vel_arr = np.column_stack((vx, vy, vz))\n",
    "        pos_rot, vel_rot = rotate_frame(pos_arr, vel_arr)\n",
    "\n",
    "        rW, warpA = measure_warp_angles(pos_rot, nbins=nbins, rmax=rmax)\n",
    "        rH, heightA = measure_scale_height(pos_rot, nbins=nbins, rmax=rmax)\n",
    "\n",
    "        label_str = f\"Snap {snap_idx} (t={t_val:.1f} Gyr)\"\n",
    "\n",
    "        axW.plot(rW, warpA, 'o-', label=label_str)\n",
    "        axH.plot(rH, heightA, 'o-', label=label_str)\n",
    "\n",
    "    axW.set_xlabel(\"Radius (kpc)\")\n",
    "    axW.set_ylabel(\"Warp Angle (deg)\")\n",
    "    axW.set_title(\"Warp Angle vs. Radius (multiple snapshots)\")\n",
    "    axW.legend()\n",
    "    axW.grid(True)\n",
    "\n",
    "    axH.set_xlabel(\"Radius (kpc)\")\n",
    "    axH.set_ylabel(\"Scale Height (kpc)\")\n",
    "    axH.set_title(\"Scale Height vs. Radius (multiple snapshots)\")\n",
    "    axH.legend()\n",
    "    axH.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(PLOTS_DIRECTORY, exist_ok=True)\n",
    "    outfile_warp = os.path.join(PLOTS_DIRECTORY, \"MultiSnap_WarpAngle.png\")\n",
    "    outfile_height = os.path.join(PLOTS_DIRECTORY, \"MultiSnap_ScaleHeight.png\")\n",
    "    figW.savefig(outfile_warp, dpi=150)\n",
    "    figH.savefig(outfile_height, dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Multi-snapshot warp & scale height plots saved to {outfile_warp} and {outfile_height}.\")\n",
    "\n",
    "print(\"Cell 5.3.3 completed: warp & scale height routines & plotting provided.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3219ea0-1405-4a99-b2f3-1447996f610f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# 1) Function to compute spiral pitch timeseries\n",
    "####################################################################\n",
    "\n",
    "def compute_spiral_pitch_timeseries(\n",
    "    rmin=1.0, \n",
    "    rmax=15.0, \n",
    "    filter_disk=True, \n",
    "    disk_type=2,\n",
    "    min_points_for_spiral=20,\n",
    "    save_results=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Loops over M33 snapshots to measure spiral pitch angle at each time,\n",
    "    returning (times_spiral, pitch_arr). \n",
    "    If any snapshot doesn't meet min_points_for_spiral, \n",
    "    we fallback to NaN or 0.0, depending on measure_spiral_pitch_angle logic.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    times_spiral : np.ndarray\n",
    "    pitch_arr    : np.ndarray\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    import logging\n",
    "    import os\n",
    "\n",
    "    m33_files = sorted(glob.glob(f\"{M33_DIRECTORY}M33_*.txt\"))\n",
    "    if len(m33_files) == 0:\n",
    "        logging.warning(\"No M33 files found for spiral pitch timeseries.\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    times_list  = []\n",
    "    pitch_list  = []\n",
    "\n",
    "    for f in m33_files:\n",
    "        snap_idx = get_snapshot_index(f)\n",
    "        if snap_idx is None:\n",
    "            continue\n",
    "\n",
    "        t_m33, count_m33, data_m33 = parse_galaxy_file(f)\n",
    "        (ptype, mass, x, y, z, vx, vy, vz) = data_m33\n",
    "\n",
    "        # shift M33\n",
    "        xcom, ycom, zcom = center_of_mass(x, y, z, mass)\n",
    "        x_shift = x - xcom\n",
    "        y_shift = y - ycom\n",
    "        z_shift = z - zcom\n",
    "        vx_shift = vx\n",
    "        vy_shift = vy\n",
    "        vz_shift = vz\n",
    "\n",
    "        if filter_disk:\n",
    "            disk_mask = (ptype == disk_type)\n",
    "            x_shift = x_shift[disk_mask]\n",
    "            y_shift = y_shift[disk_mask]\n",
    "            z_shift = z_shift[disk_mask]\n",
    "            vx_shift = vx_shift[disk_mask]\n",
    "            vy_shift = vy_shift[disk_mask]\n",
    "            vz_shift = vz_shift[disk_mask]\n",
    "\n",
    "        # if too few\n",
    "        if len(x_shift) < min_points_for_spiral:\n",
    "            pitch_list.append(np.nan)\n",
    "            times_list.append(t_m33)\n",
    "            logging.info(f\"Snapshot {snap_idx}: <{min_points_for_spiral} disk pts => pitch=NaN.\")\n",
    "            continue\n",
    "\n",
    "        # rotate\n",
    "        pos_arr = np.column_stack((x_shift, y_shift, z_shift))\n",
    "        vel_arr = np.column_stack((vx_shift, vy_shift, vz_shift))\n",
    "        pos_rot, vel_rot = rotate_frame(pos_arr, vel_arr)\n",
    "\n",
    "        # measure spiral pitch angle\n",
    "        pitch_deg, theta0_best, m_best = measure_spiral_pitch_angle(pos_rot, rmin=rmin, rmax=rmax)\n",
    "        pitch_list.append(pitch_deg)\n",
    "        times_list.append(t_m33)\n",
    "\n",
    "        logging.info(f\"Snapshot {snap_idx}: time={t_m33:.2f} => pitch={pitch_deg:.2f} deg\")\n",
    "\n",
    "    times_spiral = np.array(times_list)\n",
    "    pitch_arr    = np.array(pitch_list)\n",
    "    idx = np.argsort(times_spiral)\n",
    "    times_spiral = times_spiral[idx]\n",
    "    pitch_arr    = pitch_arr[idx]\n",
    "\n",
    "    if save_results and len(times_spiral)>0:\n",
    "        os.makedirs(RESULTS_DIRECTORY, exist_ok=True)\n",
    "        outfile = os.path.join(RESULTS_DIRECTORY, \"spiral_pitch_vs_time.npy\")\n",
    "        np.save(outfile, np.column_stack((times_spiral, pitch_arr)))\n",
    "        logging.info(f\"Spiral pitch results saved to {outfile}\")\n",
    "\n",
    "    return times_spiral, pitch_arr\n",
    "\n",
    "\n",
    "####################################################################\n",
    "# 2) Function to compute a single warp metric per snapshot\n",
    "####################################################################\n",
    "\n",
    "def compute_warp_over_time(\n",
    "    nbins=5,\n",
    "    rmax=30.0,\n",
    "    filter_disk=True,\n",
    "    disk_type=2,\n",
    "    warp_mode=\"outer\",\n",
    "    min_particles_for_warp=10,\n",
    "    save_results=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Loops over M33 snapshots to measure warp angles vs. radius,\n",
    "    then picks a single warp value (outer, mean, or max).\n",
    "    Returns (times_warp, warp_values).\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    import logging\n",
    "    import os\n",
    "\n",
    "    times_list = []\n",
    "    warp_list  = []\n",
    "\n",
    "    m33_files = sorted(glob.glob(f\"{M33_DIRECTORY}M33_*.txt\"))\n",
    "    if len(m33_files)==0:\n",
    "        logging.warning(\"No M33 files for warp timeseries.\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    for f in m33_files:\n",
    "        snap_idx = get_snapshot_index(f)\n",
    "        if snap_idx is None:\n",
    "            continue\n",
    "\n",
    "        t_m33, count_m33, data_m33 = parse_galaxy_file(f)\n",
    "        (ptype, mass, x, y, z, vx, vy, vz) = data_m33\n",
    "\n",
    "        xcom, ycom, zcom = center_of_mass(x, y, z, mass)\n",
    "        x_shift = x - xcom\n",
    "        y_shift = y - ycom\n",
    "        z_shift = z - zcom\n",
    "\n",
    "        vx_shift = vx\n",
    "        vy_shift = vy\n",
    "        vz_shift = vz\n",
    "\n",
    "        if filter_disk:\n",
    "            disk_mask = (ptype == disk_type)\n",
    "            x_shift = x_shift[disk_mask]\n",
    "            y_shift = y_shift[disk_mask]\n",
    "            z_shift = z_shift[disk_mask]\n",
    "            vx_shift = vx_shift[disk_mask]\n",
    "            vy_shift = vy_shift[disk_mask]\n",
    "            vz_shift = vz_shift[disk_mask]\n",
    "\n",
    "        if len(x_shift) < min_particles_for_warp:\n",
    "            times_list.append(t_m33)\n",
    "            warp_list.append(np.nan)\n",
    "            logging.info(f\"Snapshot {snap_idx}: <{min_particles_for_warp} disk pts => warp=NaN.\")\n",
    "            continue\n",
    "\n",
    "        pos_arr = np.column_stack((x_shift, y_shift, z_shift))\n",
    "        vel_arr = np.column_stack((vx_shift, vy_shift, vz_shift))\n",
    "        pos_rot, vel_rot = rotate_frame(pos_arr, vel_arr)\n",
    "\n",
    "        r_mid, warp_arr = measure_warp_angles(pos_rot, nbins=nbins, rmax=rmax)\n",
    "\n",
    "        valid_mask = ~np.isnan(warp_arr)\n",
    "        valid_warps = warp_arr[valid_mask]\n",
    "        if len(valid_warps)==0:\n",
    "            chosen_warp = np.nan\n",
    "        else:\n",
    "            if warp_mode==\"outer\":\n",
    "                # last valid bin\n",
    "                last_idx = np.where(valid_mask)[0][-1]\n",
    "                chosen_warp = warp_arr[last_idx]\n",
    "            elif warp_mode==\"mean\":\n",
    "                chosen_warp = np.nanmean(valid_warps)\n",
    "            elif warp_mode==\"max\":\n",
    "                chosen_warp = np.nanmax(valid_warps)\n",
    "            else:\n",
    "                chosen_warp = valid_warps[-1]\n",
    "\n",
    "        times_list.append(t_m33)\n",
    "        warp_list.append(chosen_warp)\n",
    "        logging.info(f\"Snap {snap_idx} time={t_m33:.2f} => warp={chosen_warp:.2f} deg ({warp_mode})\")\n",
    "\n",
    "    # sort by time\n",
    "    times_warp = np.array(times_list)\n",
    "    warp_values = np.array(warp_list)\n",
    "    idx_sort = np.argsort(times_warp)\n",
    "    times_warp  = times_warp[idx_sort]\n",
    "    warp_values = warp_values[idx_sort]\n",
    "\n",
    "    if save_results and len(times_warp)>0:\n",
    "        os.makedirs(RESULTS_DIRECTORY, exist_ok=True)\n",
    "        outfile = os.path.join(RESULTS_DIRECTORY, \"warp_vs_time.npy\")\n",
    "        np.save(outfile, np.column_stack((times_warp, warp_values)))\n",
    "        logging.info(f\"Warp timeseries saved to {outfile}\")\n",
    "\n",
    "    return times_warp, warp_values\n",
    "\n",
    "####################################################################\n",
    "# 3) CROSS CORRELATION USAGE\n",
    "####################################################################\n",
    "\n",
    "# Suppose we have from mass computations:\n",
    "# times_bound, Mbound_arr  # e.g. from \"Cell 3.2.2\"\n",
    "# Now we do:\n",
    "\n",
    "# 1) get spiral pitch\n",
    "times_spiral, pitch_arr = compute_spiral_pitch_timeseries(\n",
    "    rmin=1.0,\n",
    "    rmax=15.0,\n",
    "    filter_disk=True,\n",
    "    disk_type=2,\n",
    "    min_points_for_spiral=20,\n",
    "    save_results=True\n",
    ")\n",
    "\n",
    "# 2) get warp\n",
    "times_warp, warp_values = compute_warp_over_time(\n",
    "    nbins=5,\n",
    "    rmax=30.0,\n",
    "    filter_disk=True,\n",
    "    disk_type=2,\n",
    "    warp_mode=\"outer\",\n",
    "    min_particles_for_warp=10,\n",
    "    save_results=True\n",
    ")\n",
    "\n",
    "# 3) cross-correlation: mass vs. pitch and mass vs. warp\n",
    "cross_correlation_plots(\n",
    "    times_bound, Mbound_arr,\n",
    "    times_spiral, pitch_arr,\n",
    "    times_warp, warp_values,\n",
    "    outfig=\"mass_vs_pitch_and_warp.png\"\n",
    ")\n",
    "\n",
    "print(\"Hybrid pipeline: computed pitch + warp + cross-correlations with mass done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3100bf5c-6ec9-44c1-b0cb-4a54a4e63775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell 6.2 — \"Final Data Tables & Logging Info\"\n",
    "# Type: Code\n",
    "# ---------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def assemble_final_summary(times_bound, Mbound_arr,\n",
    "                           times_jacobi=None, rjacobi_arr=None,\n",
    "                           sersic_fits=None, exp_fits=None,\n",
    "                           spiral_times=None, pitch_arr=None,\n",
    "                           outcsv=\"m33_final_summary.csv\"):\n",
    "    \"\"\"\n",
    "    Combine major results into one final CSV table:\n",
    "      columns: time, Mbound, R_j, Re, n, scale_length, pitch, etc.\n",
    "    We'll do nearest-time matching or direct indexing as possible.\n",
    "\n",
    "    For a more robust solution, each set of times can be interpolated onto a common time grid.\n",
    "    For simplicity, we'll do a naive approach: for each time in times_bound, \n",
    "    we'll find the closest time in the other arrays.\n",
    "\n",
    "    Then we save to CSV for referencing in the final paper.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    times_bound, Mbound_arr : np.ndarray\n",
    "        from measure_bound_mass\n",
    "    times_jacobi, rjacobi_arr : np.ndarray or None\n",
    "        from compute_jacobi_all_snaps\n",
    "    sersic_fits, exp_fits : dict or None\n",
    "        from run_fits_for_all_snapshots => snap_idx -> (t_val, param...)\n",
    "    spiral_times, pitch_arr : np.ndarray or None\n",
    "        from compute_spiral_pitch_timeseries\n",
    "    outcsv : str\n",
    "        path to save final summary\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_summary : pd.DataFrame\n",
    "    \"\"\"\n",
    "    # We'll create a DataFrame from times_bound as the baseline\n",
    "    df = pd.DataFrame({\"time\": times_bound, \"Mbound\": Mbound_arr})\n",
    "\n",
    "    # If times_jacobi is not None, match them\n",
    "    if times_jacobi is not None and rjacobi_arr is not None and len(times_jacobi)==len(rjacobi_arr)>0:\n",
    "        # naive matching\n",
    "        Rjac_matched = []\n",
    "        for t_b in times_bound:\n",
    "            idx = np.argmin(np.abs(times_jacobi - t_b))\n",
    "            Rjac_matched.append(rjacobi_arr[idx])\n",
    "        df[\"Rjacobi\"] = Rjac_matched\n",
    "    else:\n",
    "        df[\"Rjacobi\"] = np.nan\n",
    "\n",
    "    # If sersic_fits is provided, we can do a similar approach or store by snapshot index\n",
    "    # We know times_bound is sorted by snapshot index in a naive approach.\n",
    "    # But a robust solution might require we re-check. We'll do naive approach:\n",
    "    if sersic_fits is not None:\n",
    "        Re_list, n_list = [], []\n",
    "        # We'll do a direct approach: for each time in df, find closest snapshot in sersic_fits by time\n",
    "        # build a list of (snap_idx, (time, Sigma_e, Re, n))\n",
    "        # we can flatten sersic_fits into arrays\n",
    "        s_snap = sorted(sersic_fits.keys())\n",
    "        s_times = np.array([sersic_fits[s][0] for s in s_snap])\n",
    "        revals  = np.array([sersic_fits[s][2] for s in s_snap])\n",
    "        nvals   = np.array([sersic_fits[s][3] for s in s_snap])\n",
    "\n",
    "        for t_b in df[\"time\"]:\n",
    "            idx = np.argmin(np.abs(s_times - t_b))\n",
    "            Re_list.append(revals[idx])\n",
    "            n_list.append(nvals[idx])\n",
    "        df[\"Re_sersic\"] = Re_list\n",
    "        df[\"n_sersic\"]  = n_list\n",
    "    else:\n",
    "        df[\"Re_sersic\"] = np.nan\n",
    "        df[\"n_sersic\"]  = np.nan\n",
    "\n",
    "    # If exp_fits is provided, do same approach\n",
    "    if exp_fits is not None:\n",
    "        h_list = []\n",
    "        s_snap = sorted(exp_fits.keys())\n",
    "        s_times = np.array([exp_fits[s][0] for s in s_snap])\n",
    "        hvals   = np.array([exp_fits[s][2] for s in s_snap])  # index=2 => h, since (time, Sigma0, h)\n",
    "        for t_b in df[\"time\"]:\n",
    "            idx = np.argmin(np.abs(s_times - t_b))\n",
    "            h_list.append(hvals[idx])\n",
    "        df[\"h_exp\"] = h_list\n",
    "    else:\n",
    "        df[\"h_exp\"] = np.nan\n",
    "\n",
    "    # Spiral pitch\n",
    "    if spiral_times is not None and pitch_arr is not None and len(spiral_times)>0:\n",
    "        pitch_matched = []\n",
    "        for t_b in df[\"time\"]:\n",
    "            idx = np.argmin(np.abs(spiral_times - t_b))\n",
    "            pitch_matched.append(pitch_arr[idx])\n",
    "        df[\"pitch_deg\"] = pitch_matched\n",
    "    else:\n",
    "        df[\"pitch_deg\"] = np.nan\n",
    "\n",
    "    # Now we can store final table\n",
    "    os.makedirs(RESULTS_DIRECTORY, exist_ok=True)\n",
    "    outpath = os.path.join(RESULTS_DIRECTORY, outcsv)\n",
    "    df.to_csv(outpath, index=False)\n",
    "    logging.info(f\"Final summary CSV saved to {outpath}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage for a final summary table\n",
    "df_summary = assemble_final_summary(times_bound, Mbound_arr,\n",
    "                                    times_jacobi, rjacobi_arr,\n",
    "                                    sersic_fits, exp_fits,\n",
    "                                    times_spiral, pitch_arr,\n",
    "                                    outcsv=\"m33_final_summary.csv\")\n",
    "df_summary.head(10)\n",
    "\n",
    "print(\"Cell 6.2 completed: final summary table assembled & saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cedf26-1544-48a0-8154-94265eff2e76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
