{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dd9b9c-4f98-4a43-9f56-29fc75c36dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.units as u\n",
    "import astropy.constants as const\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# GLOBAL PLOTTING STYLE\n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "plt.rcParams[\"font.size\"]      = 14\n",
    "plt.rcParams[\"axes.labelsize\"] = 14\n",
    "plt.rcParams[\"axes.titlesize\"] = 16\n",
    "plt.rcParams[\"legend.fontsize\"] = 12\n",
    "\n",
    "print(\"SECTION 1 COMPLETE: Necessary imports and global setup done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe85186-5c4e-4f4d-a1f8-8cc40dcedeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "\n",
    "# PURPOSE:\n",
    "#   1) Define a function \"Read\" that reads our snapshot files from scratch\n",
    "#   2) Demonstrate reading snapshot data for MW, M31, M33\n",
    "#   3) Store or display relevant info\n",
    "#\n",
    "# We'll re-implement the logic that was in F1ReadFile.py,\n",
    "\n",
    "def Read(filename):\n",
    "    \"\"\"\n",
    "    Function to read a GADGET-style snapshot data file and return:\n",
    "      1) Time in Myr\n",
    "      2) Total number of particles\n",
    "      3) A structured numpy array with fields: [type, m, x, y, z, vx, vy, vz]\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path to the data file, e.g. 'MW_000.txt'\n",
    "    RETURNS\n",
    "    -------\n",
    "    time  : float\n",
    "        The snapshot time in Myr\n",
    "    total : int\n",
    "        The total number of particles in the file\n",
    "    data  : np.ndarray\n",
    "        A structured array containing columns:\n",
    "          'type', 'm', 'x', 'y', 'z', 'vx', 'vy', 'vz'\n",
    "    \"\"\"\n",
    "\n",
    "    file = open(filename, 'r')\n",
    "\n",
    "    line1 = file.readline()\n",
    "    label, value = line1.split()\n",
    "    time = float(value)  # Myr\n",
    "\n",
    "    line2 = file.readline()\n",
    "    label2, value2 = line2.split()\n",
    "    total = int(value2)  # total number of particles\n",
    "\n",
    "    file.readline()\n",
    "    file.readline()\n",
    "\n",
    "    ptype_list = []\n",
    "    m_list = []\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    z_list = []\n",
    "    vx_list = []\n",
    "    vy_list = []\n",
    "    vz_list = []\n",
    "\n",
    "    for _ in range(total):\n",
    "        line = file.readline()\n",
    "        if not line:\n",
    "            # in case of truncated file\n",
    "            break\n",
    "\n",
    "        vals = line.split()\n",
    "        ptype_list.append(float(vals[0]))\n",
    "        m_list.append(float(vals[1]))\n",
    "        x_list.append(float(vals[2]))\n",
    "        y_list.append(float(vals[3]))\n",
    "        z_list.append(float(vals[4]))\n",
    "        vx_list.append(float(vals[5]))\n",
    "        vy_list.append(float(vals[6]))\n",
    "        vz_list.append(float(vals[7]))\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    dt = np.dtype([\n",
    "        ('type', float),\n",
    "        ('m', float),\n",
    "        ('x', float),\n",
    "        ('y', float),\n",
    "        ('z', float),\n",
    "        ('vx', float),\n",
    "        ('vy', float),\n",
    "        ('vz', float)\n",
    "    ])\n",
    "\n",
    "    data_array = np.zeros(total, dtype=dt)\n",
    "\n",
    "    data_array['type'] = ptype_list\n",
    "    data_array['m']    = m_list\n",
    "    data_array['x']    = x_list\n",
    "    data_array['y']    = y_list\n",
    "    data_array['z']    = z_list\n",
    "    data_array['vx']   = vx_list\n",
    "    data_array['vy']   = vy_list\n",
    "    data_array['vz']   = vz_list\n",
    "\n",
    "    return time, total, data_array\n",
    "\n",
    "\n",
    "print(\"Defined the Read() function to parse snapshot data.\")\n",
    "\n",
    "mw_file  = \"MW_000.txt\"\n",
    "m31_file = \"M31_000.txt\"\n",
    "m33_file = \"M33_000.txt\"\n",
    "\n",
    "print(\"\\nReading Milky Way Snapshot file:\", mw_file)\n",
    "mw_time, mw_total, mw_data = Read(mw_file)\n",
    "print(f\"  MW time = {mw_time} Myr, total particles = {mw_total}\")\n",
    "\n",
    "print(\"\\nReading M31 Snapshot file:\", m31_file)\n",
    "m31_time, m31_total, m31_data = Read(m31_file)\n",
    "print(f\"  M31 time = {m31_time} Myr, total particles = {m31_total}\")\n",
    "\n",
    "print(\"\\nReading M33 Snapshot file:\", m33_file)\n",
    "m33_time, m33_total, m33_data = Read(m33_file)\n",
    "print(f\"  M33 time = {m33_time} Myr, total particles = {m33_total}\")\n",
    "\n",
    "print(\"\\nSECTION 2 COMPLETE: We have snapshot data for MW, M31, and M33.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8672be-64c1-4dd5-bfc3-97f4d6e93589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3\n",
    "\n",
    "# Center-of-Mass and Orbit Computations\n",
    "#\n",
    "# We'll define a new CenterOfMass class from scratch that:\n",
    "# 1) Takes in the snapshot data array (type, m, x, y, z, vx, vy, vz)\n",
    "# 2) Filters on a chosen particle type (1=halo, 2=disk, 3=bulge)\n",
    "# 3) Implements the iterative COM approach for position (COM_P)\n",
    "# 4) Implements a method for COM velocity (COM_V)\n",
    "# \n",
    "# Then we'll compute the COM for MW, M31, and M33 as a demonstration.\n",
    "\n",
    "class CenterOfMass:\n",
    "\n",
    "    def __init__(self, data, ptype):\n",
    "        \"\"\"\n",
    "        PARAMETERS\n",
    "        ----------\n",
    "        data   : np.ndarray\n",
    "            Structured array from our Read() function, containing columns\n",
    "            'type', 'm', 'x', 'y', 'z', 'vx', 'vy', 'vz'\n",
    "        ptype  : int\n",
    "            The particle type of interest (1=Halo, 2=Disk, 3=Bulge)\n",
    "        \"\"\"\n",
    "\n",
    "        idx = np.where(data['type'] == ptype)\n",
    "        \n",
    "        self.m  = data['m'][idx]     # array of masses\n",
    "        self.x  = data['x'][idx]    \n",
    "        self.y  = data['y'][idx]    \n",
    "        self.z  = data['z'][idx]    \n",
    "        self.vx = data['vx'][idx]    \n",
    "        self.vy = data['vy'][idx]    \n",
    "        self.vz = data['vz'][idx]    \n",
    "\n",
    "    def COMdefine(self, a, b, c, m):\n",
    "        \"\"\"\n",
    "        Helper function to compute the (mass-weighted) average of\n",
    "        any 3D component vectors (like x,y,z) or (vx,vy,vz).\n",
    "        \n",
    "        PARAMETERS\n",
    "        ----------\n",
    "        a, b, c : array-like\n",
    "            Coordinates or velocities in each dimension\n",
    "        m       : array-like\n",
    "            Corresponding mass array\n",
    "        RETURNS\n",
    "        -------\n",
    "        a_com, b_com, c_com : float\n",
    "            Weighted average in each dimension\n",
    "        \"\"\"\n",
    "        a_com = np.sum(a * m) / np.sum(m)\n",
    "        b_com = np.sum(b * m) / np.sum(m)\n",
    "        c_com = np.sum(c * m) / np.sum(m)\n",
    "        return a_com, b_com, c_com\n",
    "\n",
    "    def COM_P(self, delta=0.1):\n",
    "        \"\"\"\n",
    "        Iterative method to determine the center of mass position\n",
    "        using a shrinking-sphere approach.\n",
    "\n",
    "        PARAMETERS\n",
    "        ----------\n",
    "        delta : float\n",
    "            Convergence tolerance in the distance of subsequent COM estimates (kpc)\n",
    "\n",
    "        RETURNS\n",
    "        -------\n",
    "        (xCOM, yCOM, zCOM) : tuple of floats\n",
    "            The final COM position in (kpc).\n",
    "        \"\"\"\n",
    "        # 1) Initial guess of COM using all particles\n",
    "        xCOM, yCOM, zCOM = self.COMdefine(self.x, self.y, self.z, self.m)\n",
    "        rCOM = np.sqrt(xCOM**2 + yCOM**2 + zCOM**2)\n",
    "\n",
    "        # 2) recenter the positions about this COM guess\n",
    "        x_new = self.x - xCOM\n",
    "        y_new = self.y - yCOM\n",
    "        z_new = self.z - zCOM\n",
    "        # distances of each particle from the COM\n",
    "        r_new = np.sqrt(x_new**2 + y_new**2 + z_new**2)\n",
    "\n",
    "        # 3) find the maximum distance and then half it\n",
    "        r_max = np.max(r_new) / 2.0\n",
    "\n",
    "        # define a large change so we start iterating\n",
    "        change = 1000.0\n",
    "\n",
    "        # 4) loop until the COM changes by less than delta\n",
    "        while (change > delta):\n",
    "            # select those within the reduced radius\n",
    "            idx_within = np.where(r_new < r_max)[0]\n",
    "            # compute new COM\n",
    "            x2, y2, z2 = self.COMdefine(x_new[idx_within],\n",
    "                                        y_new[idx_within],\n",
    "                                        z_new[idx_within],\n",
    "                                        self.m[idx_within])\n",
    "            r2 = np.sqrt(x2**2 + y2**2 + z2**2)\n",
    "\n",
    "            change = np.abs(rCOM - r2)\n",
    "\n",
    "            xCOM += x2\n",
    "            yCOM += y2\n",
    "            zCOM += z2\n",
    "\n",
    "            rCOM = r2\n",
    "            # recenter all particles\n",
    "            x_new = self.x - xCOM\n",
    "            y_new = self.y - yCOM\n",
    "            z_new = self.z - zCOM\n",
    "            r_new = np.sqrt(x_new**2 + y_new**2 + z_new**2)\n",
    "\n",
    "            r_max /= 2.0\n",
    "\n",
    "        return xCOM, yCOM, zCOM\n",
    "\n",
    "    def COM_V(self, xCOM, yCOM, zCOM, rvmax=15.0):\n",
    "        \"\"\"\n",
    "        Compute the center of mass velocity by selecting all\n",
    "        particles within a chosen radius (rvmax, default=15 kpc)\n",
    "        around the already-known COM position.\n",
    "\n",
    "        PARAMETERS\n",
    "        ----------\n",
    "        xCOM, yCOM, zCOM : floats\n",
    "            Known center-of-mass position for the galaxy\n",
    "        rvmax : float\n",
    "            The radius (kpc) within which to calculate velocities\n",
    "\n",
    "        RETURNS\n",
    "        -------\n",
    "        (vxCOM, vyCOM, vzCOM) : tuple of floats\n",
    "            The center-of-mass velocity in km/s\n",
    "        \"\"\"\n",
    "        # distances from that COM\n",
    "        dx = self.x - xCOM\n",
    "        dy = self.y - yCOM\n",
    "        dz = self.z - zCOM\n",
    "        rr = np.sqrt(dx**2 + dy**2 + dz**2)\n",
    "        # select those within rvmax\n",
    "        idx = np.where(rr < rvmax)[0]\n",
    "        # compute COM velocity\n",
    "        vxCOM, vyCOM, vzCOM = self.COMdefine(self.vx[idx],\n",
    "                                             self.vy[idx],\n",
    "                                             self.vz[idx],\n",
    "                                             self.m[idx])\n",
    "        return vxCOM, vyCOM, vzCOM\n",
    "\n",
    "print(\"A new 'CenterOfMass' class has been defined from scratch.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c163ac47-f81c-4cbc-8a2d-702858170dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4\n",
    "\n",
    "# 1) MW center of mass, using disk particles (ptype=2):\n",
    "MW_COM_disk = CenterOfMass(mw_data, ptype=2)\n",
    "MW_xcom, MW_ycom, MW_zcom = MW_COM_disk.COM_P(delta=0.1)\n",
    "MW_vxcom, MW_vycom, MW_vzcom = MW_COM_disk.COM_V(MW_xcom, MW_ycom, MW_zcom)\n",
    "\n",
    "print(\"\\n--- Milky Way COM (Disk) ---\")\n",
    "print(f\"Position: x={MW_xcom:.3f}, y={MW_ycom:.3f}, z={MW_zcom:.3f} (kpc)\")\n",
    "print(f\"Velocity: vx={MW_vxcom:.3f}, vy={MW_vycom:.3f}, vz={MW_vzcom:.3f} (km/s)\")\n",
    "\n",
    "# 2) M31 center of mass, disk as well:\n",
    "M31_COM_disk = CenterOfMass(m31_data, ptype=2)\n",
    "M31_xcom, M31_ycom, M31_zcom = M31_COM_disk.COM_P(delta=0.1)\n",
    "M31_vxcom, M31_vycom, M31_vzcom = M31_COM_disk.COM_V(M31_xcom, M31_ycom, M31_zcom)\n",
    "\n",
    "print(\"\\n--- M31 COM (Disk) ---\")\n",
    "print(f\"Position: x={M31_xcom:.3f}, y={M31_ycom:.3f}, z={M31_zcom:.3f} (kpc)\")\n",
    "print(f\"Velocity: vx={M31_vxcom:.3f}, vy={M31_vycom:.3f}, vz={M31_vzcom:.3f} (km/s)\")\n",
    "\n",
    "# 3) M33 center of mass, disk again (ptype=2):\n",
    "M33_COM_disk = CenterOfMass(m33_data, ptype=2)\n",
    "M33_xcom, M33_ycom, M33_zcom = M33_COM_disk.COM_P(delta=0.1)\n",
    "M33_vxcom, M33_vycom, M33_vzcom = M33_COM_disk.COM_V(M33_xcom, M33_ycom, M33_zcom)\n",
    "\n",
    "print(\"\\n--- M33 COM (Disk) ---\")\n",
    "print(f\"Position: x={M33_xcom:.3f}, y={M33_ycom:.3f}, z={M33_zcom:.3f} (kpc)\")\n",
    "print(f\"Velocity: vx={M33_vxcom:.3f}, vy={M33_vycom:.3f}, vz={M33_vzcom:.3f} (km/s)\")\n",
    "\n",
    "# RELATIVE POSITIONS (e.g., M33 w.r.t M31)\n",
    "dx_31_33 = M33_xcom - M31_xcom\n",
    "dy_31_33 = M33_ycom - M31_ycom\n",
    "dz_31_33 = M33_zcom - M31_zcom\n",
    "r_31_33 = np.sqrt(dx_31_33**2 + dy_31_33**2 + dz_31_33**2)\n",
    "\n",
    "print(f\"\\nM33 - M31 Separation: {r_31_33:.3f} kpc\")\n",
    "\n",
    "print(\"\\nSECTION 3 COMPLETE: We have computed COM for each galaxy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d1a8a-5031-48aa-a918-5e53ae463a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5\n",
    "\n",
    "#build COM catalogue for all snapshots\n",
    "\n",
    "galaxy_folders = [\"MW\", \"M31\", \"M33\"]\n",
    "ptype_list     = [1, 2, 3]          # 1 = Halo, 2 = Disk, 3 = Bulge\n",
    "records        = []\n",
    "\n",
    "# helper to squash NaN / Inf to 0.0  (avoids six identical if‑blocks)\n",
    "_clean = lambda v: 0.0 if (np.isnan(v) or np.isinf(v)) else v\n",
    "\n",
    "for gal in galaxy_folders:\n",
    "    for filename in sorted(glob.glob(f\"{gal}/{gal}_*.txt\")):\n",
    "        time_myr, total_p, data_array = Read(filename)\n",
    "        snap_str = filename.split(\"_\")[-1].replace(\".txt\", \"\")\n",
    "\n",
    "        for ptype in ptype_list:\n",
    "            com      = CenterOfMass(data_array, ptype)\n",
    "            # COM position / velocity (fall back to zeros on failure)\n",
    "            try:\n",
    "                xcom, ycom, zcom = com.COM_P(delta=0.1)\n",
    "                vxcom, vycom, vzcom = com.COM_V(xcom, ycom, zcom, rvmax=15.0)\n",
    "            except Exception:\n",
    "                xcom = ycom = zcom = vxcom = vycom = vzcom = 0.0\n",
    "\n",
    "            # clean NaN / Inf once, with helper\n",
    "            xcom, ycom, zcom = map(_clean, (xcom, ycom, zcom))\n",
    "            vxcom, vycom, vzcom = map(_clean, (vxcom, vycom, vzcom))\n",
    "\n",
    "            records.append(\n",
    "                dict(galaxy=gal, snapshot=snap_str, time_Myr=time_myr,\n",
    "                     ptype=ptype, xcom=xcom, ycom=ycom, zcom=zcom,\n",
    "                     vxcom=vxcom, vycom=vycom, vzcom=vzcom)\n",
    "            )\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(\"All_COM.csv\", index=False)\n",
    "print(f\"Saved COM data to All_COM.csv with {len(df)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3dff62-4532-4acf-9aad-26c7f75057f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6\n",
    "\n",
    "# Define a MassProfile class\n",
    "#\n",
    "# PURPOSE:\n",
    "# For a galaxy's snapshot data (mw_data, m31_data, or m33_data) plus that galaxy's center (xCOM,yCOM,zCOM),\n",
    "# we can compute the enclosed mass at any given radius for each ptype or the total.\n",
    "\n",
    "class MassProfile:\n",
    "    \"\"\"\n",
    "    Class that computes the mass profile for a snapshot of a galaxy,\n",
    "    given the galaxy's COM position, so we can measure distances from COM.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, xCOM, yCOM, zCOM):\n",
    "        \"\"\"\n",
    "        PARAMETERS\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Structured array with columns 'type', 'm', 'x', 'y', 'z', ...\n",
    "        xCOM, yCOM, zCOM : float\n",
    "            The center-of-mass (in kpc) for this galaxy\n",
    "        \"\"\"\n",
    "        self.data = data  # entire structured array\n",
    "        self.xCOM = xCOM\n",
    "        self.yCOM = yCOM\n",
    "        self.zCOM = zCOM\n",
    "\n",
    "        # G in convenient units: kpc (km/s)^2 / Msun\n",
    "        self.G = 4.498768e-6\n",
    "\n",
    "    def _distance_from_com(self, x, y, z):\n",
    "        \"\"\"\n",
    "        Internal helper function to compute 3D distance from COM\n",
    "        for each particle. Returns array of distances in kpc.\n",
    "        \"\"\"\n",
    "        dx = x - self.xCOM\n",
    "        dy = y - self.yCOM\n",
    "        dz = z - self.zCOM\n",
    "        rr = np.sqrt(dx*dx + dy*dy + dz*dz)\n",
    "        return rr\n",
    "\n",
    "    def MassEnclosed(self, ptype, radius):\n",
    "        \"\"\"\n",
    "        Compute the enclosed mass for a specific ptype (1=Halo,2=Disk,3=Bulge)\n",
    "        within a given radius (or array of radii).\n",
    "\n",
    "        PARAMETERS\n",
    "        ----------\n",
    "        ptype : int\n",
    "            Particle type (1,2,3)\n",
    "        radius : float or array-like\n",
    "            Single radius in kpc, or an array of radii in kpc\n",
    "\n",
    "        RETURNS\n",
    "        -------\n",
    "        Menc : float or np.ndarray\n",
    "            The enclosed mass in Msun, same shape as 'radius'\n",
    "        \"\"\"\n",
    "        # Filter the data for just that ptype\n",
    "        idx = np.where(self.data['type'] == ptype)[0]\n",
    "        mass_arr = self.data['m'][idx]  # in 1e10 Msun\n",
    "        x_arr = self.data['x'][idx]\n",
    "        y_arr = self.data['y'][idx]\n",
    "        z_arr = self.data['z'][idx]\n",
    "\n",
    "        rr = self._distance_from_com(x_arr, y_arr, z_arr)\n",
    "\n",
    "        r_array = np.atleast_1d(radius)\n",
    "\n",
    "        Menc_list = []\n",
    "        for rmax in r_array:\n",
    "            inside_idx = np.where(rr < rmax)[0]\n",
    "            mass_enclosed = np.sum(mass_arr[inside_idx]) * 1e10  # Msun\n",
    "            Menc_list.append(mass_enclosed)\n",
    "\n",
    "        if len(Menc_list) == 1:\n",
    "            return Menc_list[0]\n",
    "        else:\n",
    "            return np.array(Menc_list)\n",
    "\n",
    "    def MassEnclosedTotal(self, radius):\n",
    "        \"\"\"\n",
    "        Sum of halo, disk, and bulge within 'radius'.\n",
    "        (We assume ptype=1,2,3 are the only ones.)\n",
    "\n",
    "        RETURNS\n",
    "        -------\n",
    "        Mtot : float or array, Msun\n",
    "        \"\"\"\n",
    "        M1 = self.MassEnclosed(1, radius)  # halo\n",
    "        M2 = self.MassEnclosed(2, radius)  # disk\n",
    "        M3 = self.MassEnclosed(3, radius)  # bulge if it exists\n",
    "        return M1 + M2 + M3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf051f2-c1bf-429c-a9f8-ad39345c6918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7\n",
    "\n",
    "def compute_jacobi_radius(r_m31_m33, M_m33, Menc_m31):\n",
    "    \"\"\"Jacobi radius: R_J = r * (M_M33 / (2 M_enc_M31))^(1/3)\"\"\"\n",
    "    return 0.0 if Menc_m31 <= 0 else r_m31_m33 * (M_m33 / (2.0*Menc_m31))**(1/3)\n",
    "\n",
    "def jacobi_usage():\n",
    "    \"\"\"\n",
    "    1) Load COM data           3) build MassProfile for M31\n",
    "    2) loop over snapshots     4) compute Jacobi radius\n",
    "    5) save to JacobiRadius.csv\n",
    "    \"\"\"\n",
    "    com_df = pd.read_csv(\"All_COM.csv\")\n",
    "    # ensure numeric snapshot column once\n",
    "    if 'snap_int' not in com_df.columns:\n",
    "        com_df['snap_int'] = com_df['snapshot'].astype(int)\n",
    "    all_snaps = sorted(com_df['snap_int'].unique())\n",
    "\n",
    "    def get_com_row(gal, snap, ptype):\n",
    "        return com_df.query(\n",
    "            \"(galaxy == @gal) & (ptype == @ptype) & (snap_int == @snap)\"\n",
    "        ).squeeze()  \n",
    "\n",
    "    jaco_records = []\n",
    "    for snap in all_snaps:\n",
    "        snap_str = f\"{snap:03d}\"\n",
    "        m31_file = f\"M31/M31_{snap_str}.txt\"\n",
    "        m33_file = f\"M33/M33_{snap_str}.txt\"\n",
    "        if not (os.path.exists(m31_file) and os.path.exists(m33_file)):\n",
    "            continue\n",
    "\n",
    "        _, _, data_m31 = Read(m31_file)\n",
    "        _, _, data_m33 = Read(m33_file)\n",
    "\n",
    "        row_m31 = get_com_row(\"M31\", snap, 2)\n",
    "        row_m33 = get_com_row(\"M33\", snap, 2)\n",
    "        if row_m31.empty or row_m33.empty:\n",
    "            continue\n",
    "\n",
    "        # separation\n",
    "        dx = row_m33.xcom - row_m31.xcom\n",
    "        dy = row_m33.ycom - row_m31.ycom\n",
    "        dz = row_m33.zcom - row_m31.zcom\n",
    "        r_m31_m33 = np.sqrt(dx*dx + dy*dy + dz*dz)\n",
    "\n",
    "        M31prof   = MassProfile(data_m31, row_m31.xcom, row_m31.ycom, row_m31.zcom)\n",
    "        Menc_m31  = M31prof.MassEnclosedTotal(r_m31_m33)\n",
    "\n",
    "        M33prof   = MassProfile(data_m33, row_m33.xcom, row_m33.ycom, row_m33.zcom)\n",
    "        M33_total = M33prof.MassEnclosedTotal(300.0)\n",
    "\n",
    "        RJ = compute_jacobi_radius(r_m31_m33, M33_total, Menc_m31)\n",
    "\n",
    "        jaco_records.append(dict(snapshot=snap_str, snap_int=snap,\n",
    "                                 time_Myr=row_m31.time_Myr,\n",
    "                                 r_M31_M33=r_m31_m33, M31_enc=Menc_m31,\n",
    "                                 M33_total=M33_total, JacobiR=RJ))\n",
    "\n",
    "    pd.DataFrame(jaco_records).to_csv(\"JacobiRadius.csv\", index=False)\n",
    "    print(f\"Saved {len(jaco_records)} rows to JacobiRadius.csv.\")\n",
    "\n",
    "# now run\n",
    "# jacobi_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f605dbbb-2b3f-4822-aefd-832de7a20cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8\n",
    "\n",
    "df_jacobi = pd.read_csv(\"JacobiRadius.csv\")\n",
    "plt.plot(df_jacobi[\"time_Myr\"], df_jacobi[\"JacobiR\"], '-')\n",
    "plt.xlabel(\"Time (Myr)\")\n",
    "plt.ylabel(\"Jacobi Radius (kpc)\")\n",
    "plt.title(\"Evolution of Jacobi Radius Over Time\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95153587-a912-4e56-82c3-0d9f96c94e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 ── M 33 stellar‑mass loss versus Jacobi radius\n",
    "# (pandas, numpy already imported earlier)\n",
    "\n",
    "def mass_loss_m33():\n",
    "    \"\"\"\n",
    "    For every snapshot:\n",
    "        • read M33 file and its COM (ptype = 2)\n",
    "        • take Jacobi radius R_J from JacobiRadius.csv\n",
    "        • sum stellar mass (ptype = 2 or 3) inside R_J\n",
    "        • compare to initial stellar mass (snapshot 0) → bound fraction\n",
    "    Saves results to M33_MassLoss.csv\n",
    "    \"\"\"\n",
    "    jaco_df = pd.read_csv(\"JacobiRadius.csv\")\n",
    "    com_df  = pd.read_csv(\"All_COM.csv\")\n",
    "\n",
    "    # ensure numeric snapshot column exists once\n",
    "    if 'snap_int' not in jaco_df.columns:\n",
    "        jaco_df['snap_int'] = jaco_df['snapshot'].astype(int)\n",
    "    if 'snap_int' not in com_df.columns:\n",
    "        com_df['snap_int']  = com_df['snapshot'].astype(int)\n",
    "\n",
    "    m33_com_df = com_df.query(\"(galaxy == 'M33') & (ptype == 2)\")\n",
    "\n",
    "    # ---------- helpers ----------------------------------------------------\n",
    "    def get_jacobi_and_com(snap_int):\n",
    "        \"\"\"Return (time, R_J, xCOM, yCOM, zCOM) for a given snapshot.\"\"\"\n",
    "        row_j = jaco_df.query(\"snap_int == @snap_int\")\n",
    "        row_c = m33_com_df.query(\"snap_int == @snap_int\")\n",
    "        if len(row_j) != 1 or len(row_c) != 1:\n",
    "            return None\n",
    "        return (row_j.time_Myr.values[0], row_j.JacobiR.values[0],\n",
    "                row_c.xcom.values[0],   row_c.ycom.values[0],  row_c.zcom.values[0])\n",
    "    # -----------------------------------------------------------------------\n",
    "\n",
    "    # --- initial stellar mass (snapshot 0 or earliest available) -----------\n",
    "    zero_snap = 0 if 0 in jaco_df.snap_int.values else jaco_df.snap_int.min()\n",
    "    init_vals = get_jacobi_and_com(zero_snap)\n",
    "    if init_vals is None:\n",
    "        print(\"No valid snapshot for initial mass. Aborting.\")\n",
    "        return\n",
    "    t0, RJ0, x0, y0, z0 = init_vals\n",
    "\n",
    "    init_file = f\"M33/M33_{zero_snap:03d}.txt\"\n",
    "    _, _, data0 = Read(init_file)\n",
    "\n",
    "    star_idx0 = np.where((data0['type'] == 2) | (data0['type'] == 3))[0]\n",
    "    # total stellar mass (no radius cut, same as original)\n",
    "    M33_init_star = np.sum(data0['m'][star_idx0]) * 1e10  # Msun\n",
    "    print(f\"Initial M33 stellar mass (snapshot {zero_snap:03d}) = {M33_init_star:.2e} Msun\")\n",
    "\n",
    "    # ---------------- iterate over snapshots ------------------------------\n",
    "    bound_records = []\n",
    "    for snap in sorted(jaco_df.snap_int.unique()):\n",
    "        vals = get_jacobi_and_com(snap)\n",
    "        if vals is None:\n",
    "            continue\n",
    "        time_myr, RJ, xcom, ycom, zcom = vals\n",
    "\n",
    "        m33_file = f\"M33/M33_{snap:03d}.txt\"\n",
    "        if not os.path.exists(m33_file):\n",
    "            continue\n",
    "\n",
    "        _, _, data = Read(m33_file)\n",
    "        star_idx = np.where((data['type'] == 2) | (data['type'] == 3))[0]\n",
    "\n",
    "        # distance of stellar particles from COM\n",
    "        rr = dist3d(data['x'][star_idx], data['y'][star_idx], data['z'][star_idx],\n",
    "                    xcom, ycom, zcom)\n",
    "\n",
    "        inside_idx = star_idx[np.where(rr < RJ)]\n",
    "        Mstar_bound = np.sum(data['m'][inside_idx]) * 1e10  # Msun\n",
    "        frac_bound  = Mstar_bound / M33_init_star\n",
    "\n",
    "        bound_records.append(dict(snapshot=f\"{snap:03d}\", snap_int=snap,\n",
    "                                  time_Myr=time_myr, JacobiR=RJ,\n",
    "                                  Mstar_bound=Mstar_bound, frac_bound=frac_bound))\n",
    "\n",
    "    pd.DataFrame(bound_records).to_csv(\"M33_MassLoss.csv\", index=False)\n",
    "    print(f\"Mass‑loss results saved to M33_MassLoss.csv with {len(bound_records)} rows.\")\n",
    "\n",
    "\n",
    "# run the analysis\n",
    "# mass_loss_m33()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f5246a-4dbb-4bb4-b653-b639650ca286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 ── plot M 33 mass‑loss history  (imports already present)\n",
    "\n",
    "def plot_m33_mass_loss():\n",
    "    df_loss = pd.read_csv(\"M33_MassLoss.csv\")\n",
    "    if df_loss.empty:\n",
    "        print(\"No data in M33_MassLoss.csv. Exiting.\")\n",
    "        return\n",
    "\n",
    "    initial_mass = df_loss.Mstar_bound.iloc[0] / df_loss.frac_bound.iloc[0]\n",
    "    final_mass   = df_loss.Mstar_bound.iloc[-1]\n",
    "    frac_lost    = 1.0 - df_loss.frac_bound.iloc[-1]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(df_loss.time_Myr, df_loss.frac_bound, '-', label=\"M33 Bound Fraction\")\n",
    "\n",
    "    legend_title = (f\"Initial = {initial_mass:.2e} Msun\\n\"\n",
    "                    f\"Final   = {final_mass:.2e} Msun\\n\"\n",
    "                    f\"Lost    = {frac_lost*100:.1f}%\")\n",
    "    ax.legend(title=legend_title)\n",
    "\n",
    "    ax.set_xlabel(\"Time (Myr)\")\n",
    "    ax.set_ylabel(\"Fraction of M33 Stellar Mass Bound\")\n",
    "    ax.set_title(\"M33 Mass Loss Over Time\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_m33_mass_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb2dd3d-8fb5-4068-84f9-e1234e39ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# Face‑on transformation, surface‑density profile & fitting tools\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "\n",
    "def rotate_to_face_on(positions, velocities):\n",
    "    \"\"\"\n",
    "    Rotate a disk to face‑on by aligning the total angular‑momentum vector\n",
    "    with the z‑axis.  Returns new_pos, new_vel (N, 3) arrays.\n",
    "    \"\"\"\n",
    "    L = np.sum(np.cross(positions, velocities), axis=0)\n",
    "    Lmag = np.linalg.norm(L)\n",
    "    if Lmag == 0:\n",
    "        return positions, velocities\n",
    "    Lhat = L / Lmag\n",
    "\n",
    "    zhat = np.array([0, 0, 1.0])\n",
    "    v    = np.cross(Lhat, zhat)\n",
    "    s    = np.linalg.norm(v)\n",
    "    c    = np.dot(Lhat, zhat)\n",
    "    if s == 0:                         # already aligned\n",
    "        return positions, velocities\n",
    "\n",
    "    vx  = np.array([[   0, -v[2],  v[1]],\n",
    "                    [ v[2],    0, -v[0]],\n",
    "                    [-v[1],  v[0],    0]])\n",
    "    R   = np.eye(3) + vx + vx @ vx * ((1 - c) / s**2)\n",
    "\n",
    "    return positions @ R.T, velocities @ R.T\n",
    "\n",
    "\n",
    "def surface_density_profile(positions, nbins=50, rmax=None):\n",
    "    \"\"\"\n",
    "    Number‑based radial surface‑density profile for a face‑on disk.\n",
    "    Returns r_mid, sigma.\n",
    "    \"\"\"\n",
    "    r = np.hypot(positions[:, 0], positions[:, 1])\n",
    "    if rmax is None:\n",
    "        rmax = np.percentile(r, 99.0)\n",
    "\n",
    "    edges  = np.linspace(0, rmax, nbins + 1)\n",
    "    r_mid  = 0.5 * (edges[1:] + edges[:-1])\n",
    "    sigma  = np.zeros(nbins)\n",
    "\n",
    "    for i in range(nbins):\n",
    "        r_in, r_out = edges[i], edges[i + 1]\n",
    "        area        = np.pi * (r_out**2 - r_in**2)\n",
    "        sigma[i]    = np.count_nonzero((r >= r_in) & (r < r_out)) / area\n",
    "    return r_mid, sigma\n",
    "\n",
    "\n",
    "# --- fitting functions ----------------------------------------------------\n",
    "\n",
    "def sersic_function(r, I0, re, n):\n",
    "    b = 2.0 * n - 1.0 / 3.0                 # rough b(n) approximation\n",
    "    return I0 * np.exp(-b * ((r / re)**(1 / n) - 1.0))\n",
    "\n",
    "\n",
    "def exponential_function(r, I0, rd):\n",
    "    return I0 * np.exp(-r / rd)\n",
    "\n",
    "\n",
    "def fit_sersic(r, sigma, guess=(1.0, 1.0, 1.0), use_exponential=False):\n",
    "    \"\"\"\n",
    "    Fit either a Sersic (default) or exponential (if use_exponential=True)\n",
    "    to the (r, sigma) profile.  Returns popt, pcov from curve_fit.\n",
    "    \"\"\"\n",
    "    mask = sigma > 0\n",
    "    r_fit, y_fit = r[mask], sigma[mask]\n",
    "    if r_fit.size < 3:\n",
    "        return None, None\n",
    "    try:\n",
    "        if use_exponential:\n",
    "            return curve_fit(exponential_function, r_fit, y_fit, p0=guess[:2])\n",
    "        else:\n",
    "            return curve_fit(sersic_function,      r_fit, y_fit, p0=guess)\n",
    "    except Exception:                       # fit failed\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# Main analysis: M33 disk‑profile evolution\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "\n",
    "def disk_profile():\n",
    "    \"\"\"\n",
    "    Loop over all M33 snapshots, rotate the stellar disk face‑on, build a\n",
    "    radial surface‑density profile, fit exponential & Sersic models, and\n",
    "    save the fit parameters to *M33_DiskProfileFits.csv*.\n",
    "    \"\"\"\n",
    "    com_df  = pd.read_csv(\"All_COM.csv\")\n",
    "    m33_df  = com_df.query(\"(galaxy == 'M33') & (ptype == 2)\").copy()\n",
    "    if 'snap_int' not in m33_df.columns:\n",
    "        m33_df['snap_int'] = m33_df['snapshot'].astype(int)\n",
    "\n",
    "    records = []\n",
    "    for snap in sorted(m33_df.snap_int.unique()):\n",
    "        row = m33_df.loc[m33_df.snap_int == snap].squeeze()\n",
    "        if row.empty:\n",
    "            continue\n",
    "\n",
    "        xcom, ycom, zcom, time_myr = row[['xcom', 'ycom', 'zcom', 'time_Myr']]\n",
    "        fname = f\"M33/M33_{snap:03d}.txt\"\n",
    "        if not os.path.exists(fname):\n",
    "            continue\n",
    "\n",
    "        _, _, data = Read(fname)\n",
    "        star_idx   = np.where((data['type'] == 2) | (data['type'] == 3))[0]\n",
    "\n",
    "        pos = np.column_stack((data['x'][star_idx] - xcom,\n",
    "                               data['y'][star_idx] - ycom,\n",
    "                               data['z'][star_idx] - zcom))\n",
    "        vel = np.column_stack((data['vx'][star_idx],\n",
    "                               data['vy'][star_idx],\n",
    "                               data['vz'][star_idx]))\n",
    "\n",
    "        pos_face, _ = rotate_to_face_on(pos, vel)\n",
    "\n",
    "        r_mid, sigma = surface_density_profile(pos_face, nbins=40, rmax=20.0)\n",
    "        popt_exp, _  = fit_sersic(r_mid, sigma,\n",
    "                                  guess=(sigma.max(), 2.0),\n",
    "                                  use_exponential=True)\n",
    "        popt_ser, _  = fit_sersic(r_mid, sigma,\n",
    "                                  guess=(sigma.max(), 2.0, 1.0),\n",
    "                                  use_exponential=False)\n",
    "\n",
    "        records.append({\n",
    "            \"snapshot\"   : snap,\n",
    "            \"time_Myr\"   : time_myr,\n",
    "            \"exp_I0\"     : popt_exp[0] if popt_exp is not None else 0.0,\n",
    "            \"exp_r_d\"    : popt_exp[1] if popt_exp is not None else 0.0,\n",
    "            \"sersic_I0\"  : popt_ser[0] if popt_ser is not None else 0.0,\n",
    "            \"sersic_re\"  : popt_ser[1] if popt_ser is not None else 0.0,\n",
    "            \"sersic_n\"   : popt_ser[2] if popt_ser is not None else 0.0\n",
    "        })\n",
    "\n",
    "    pd.DataFrame(records).to_csv(\"M33_DiskProfileFits.csv\", index=False)\n",
    "    print(f\"Created M33_DiskProfileFits.csv with {len(records)} rows.\")\n",
    "\n",
    "\n",
    "# ---- optional execution ---------------------------------------------------\n",
    "# disk_profile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e8124-fc23-46cb-9dbe-e978bba7143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12\n",
    "\n",
    "def compute_disk_kinematics(new_pos, new_vel, nbins=20, rmax=None):\n",
    "    \"\"\"\n",
    "    Given face‑on positions/velocities, return σ_rad, σ_tan, σ_z in radial bins.\n",
    "    \"\"\"\n",
    "    x, y, z = new_pos.T\n",
    "    vx, vy, vz = new_vel.T\n",
    "\n",
    "    r   = np.hypot(x, y)\n",
    "    phi = np.arctan2(y, x)\n",
    "\n",
    "    v_rad =  vx*np.cos(phi) + vy*np.sin(phi)\n",
    "    v_tan = -vx*np.sin(phi) + vy*np.cos(phi)\n",
    "\n",
    "    if rmax is None:\n",
    "        rmax = np.percentile(r, 99.0)\n",
    "\n",
    "    edges      = np.linspace(0, rmax, nbins + 1)\n",
    "    r_mid      = 0.5 * (edges[:-1] + edges[1:])\n",
    "    sigma_rad  = np.zeros(nbins)\n",
    "    sigma_tan  = np.zeros(nbins)\n",
    "    sigma_z    = np.zeros(nbins)\n",
    "\n",
    "    for i, (rin, rout) in enumerate(zip(edges[:-1], edges[1:])):\n",
    "        idx = (r >= rin) & (r < rout)\n",
    "        if idx.sum() >= 2:                          # need ≥2 points for std\n",
    "            sigma_rad[i] = np.std(v_rad[idx])\n",
    "            sigma_tan[i] = np.std(v_tan[idx])\n",
    "            sigma_z[i]   = np.std(vz[idx])\n",
    "\n",
    "    return r_mid, sigma_rad, sigma_tan, sigma_z\n",
    "\n",
    "\n",
    "def disk_kinematics_demo():\n",
    "    \"\"\"\n",
    "    Rotate each M33 snapshot face‑on, measure σ’s in radial bins,\n",
    "    and save to *M33_Kinematics.csv* in long format.\n",
    "    \"\"\"\n",
    "    com_df  = pd.read_csv(\"All_COM.csv\")\n",
    "    m33_df  = com_df.query(\"(galaxy == 'M33') & (ptype == 2)\").copy()\n",
    "    if 'snap_int' not in m33_df.columns:\n",
    "        m33_df['snap_int'] = m33_df['snapshot'].astype(int)\n",
    "\n",
    "    records = []\n",
    "    for snap in sorted(m33_df.snap_int.unique()):\n",
    "        row = m33_df.loc[m33_df.snap_int == snap].squeeze()\n",
    "        if row.empty:\n",
    "            continue\n",
    "\n",
    "        xcom, ycom, zcom, time_myr = row[['xcom', 'ycom', 'zcom', 'time_Myr']]\n",
    "        fname = f\"M33/M33_{snap:03d}.txt\"\n",
    "        if not os.path.exists(fname):\n",
    "            continue\n",
    "\n",
    "        _, _, data = Read(fname)\n",
    "        star_idx   = np.where((data['type'] == 2) | (data['type'] == 3))[0]\n",
    "\n",
    "        pos = np.column_stack((data['x'][star_idx] - xcom,\n",
    "                               data['y'][star_idx] - ycom,\n",
    "                               data['z'][star_idx] - zcom))\n",
    "        vel = np.column_stack((data['vx'][star_idx],\n",
    "                               data['vy'][star_idx],\n",
    "                               data['vz'][star_idx]))\n",
    "\n",
    "        pos_face, vel_face = rotate_to_face_on(pos, vel)\n",
    "        r_mid, s_r, s_t, s_z = compute_disk_kinematics(pos_face, vel_face,\n",
    "                                                       nbins=20, rmax=20.0)\n",
    "\n",
    "        # long‑format rows\n",
    "        for i in range(len(r_mid)):\n",
    "            records.append(dict(snapshot=snap, time_Myr=time_myr,\n",
    "                                bin_index=i, r_mid=r_mid[i],\n",
    "                                sigma_rad=s_r[i], sigma_tan=s_t[i], sigma_z=s_z[i]))\n",
    "\n",
    "    pd.DataFrame(records).to_csv(\"M33_Kinematics.csv\", index=False)\n",
    "    print(f\"disk_kinematics_demo finished — wrote {len(records)} rows.\")\n",
    "\n",
    "\n",
    "# disk_kinematics_demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae2176-8b0f-4e00-b8f3-78313eae5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14\n",
    "\n",
    "df_kin = pd.read_csv(\"M33_Kinematics.csv\")\n",
    "df_100 = df_kin[df_kin['snapshot']==100]\n",
    "plt.plot(df_100['r_mid'], df_100['sigma_z'], 'o-')\n",
    "plt.xlabel(\"Radius (kpc)\")\n",
    "plt.ylabel(\"Vertical Velocity Dispersion (km/s)\")\n",
    "plt.title(\"M33 Kinematics at snapshot=100\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d6178-1f53-4f61-9b41-283d66d399fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15\n",
    "\n",
    "def final_reporting():\n",
    "    \"\"\"\n",
    "    Creates final plots/tables for the paper:\n",
    "      1) M33 mass fraction vs time (from M33_MassLoss.csv)\n",
    "      2) M33 disk profile fits (from M33_DiskProfileFits.csv)\n",
    "      3) M33 disk velocity dispersions, but one figure per snapshot (from M33_Kinematics.csv)\n",
    "      4) Summaries saved in a text/csv in 'figures/'.\n",
    "\n",
    "    Adjust as needed for your final suite of results.\n",
    "    \"\"\"\n",
    "\n",
    "    ########################################################################\n",
    "    # 0) Make a 'figures' folder if not present\n",
    "    ########################################################################\n",
    "    if not os.path.exists(\"figures\"):\n",
    "        os.mkdir(\"figures\")\n",
    "\n",
    "    ########################################################################\n",
    "    # 1) Plot M33 disk profile fits (M33_DiskProfileFits.csv)\n",
    "    ########################################################################\n",
    "    diskfits_file = \"M33_DiskProfileFits.csv\"\n",
    "    if os.path.exists(diskfits_file):\n",
    "        df_fits = pd.read_csv(diskfits_file)\n",
    "        # typical columns: snapshot, time_Myr, exp_I0, exp_r_d, sersic_I0, sersic_re, sersic_n\n",
    "\n",
    "        fig, ax = plt.subplots(2, 1, figsize=(12,10), dpi=120)\n",
    "\n",
    "        # Subplot 1: Exponential scale length\n",
    "        ax[0].plot(df_fits[\"time_Myr\"], df_fits[\"exp_r_d\"], '-', label='exp_r_d')\n",
    "        ax[0].set_xlabel(\"Time (Myr)\")\n",
    "        ax[0].set_ylabel(\"Exponential Scale Length (kpc)\")\n",
    "        ax[0].set_title(\"M33 Disk Scale Length Over Time\")\n",
    "        ax[0].legend()\n",
    "\n",
    "        # Subplot 2: Sersic n\n",
    "        ax[1].plot(df_fits[\"time_Myr\"], df_fits[\"sersic_n\"], '-', label='sersic_n')\n",
    "        ax[1].set_xlabel(\"Time (Myr)\")\n",
    "        ax[1].set_ylabel(\"Sersic Index n\")\n",
    "        ax[1].set_title(\"M33 Sersic Index Over Time\")\n",
    "        ax[1].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"M33_DiskProfileFits.png\")\n",
    "        plt.close(fig)\n",
    "        print(\"Saved M33_DiskProfileFits.png\")\n",
    "\n",
    "    ########################################################################\n",
    "    # 2) Disk Kinematics: We handle M33_Kinematics.csv\n",
    "    #    But we produce a SEPARATE figure for each snapshot => no huge multi-subplot\n",
    "    ########################################################################\n",
    "    kin_file = \"M33_Kinematics.csv\"\n",
    "    if os.path.exists(kin_file):\n",
    "        df_kin = pd.read_csv(kin_file)\n",
    "        # columns: snapshot, time_Myr, bin_index, r_mid, sigma_rad, sigma_tan, sigma_z\n",
    "        # We'll identify unique snapshots\n",
    "        unique_snaps = sorted(df_kin[\"snapshot\"].unique())\n",
    "\n",
    "        for snap in unique_snaps:\n",
    "            sub = df_kin[df_kin[\"snapshot\"]==snap]\n",
    "            if len(sub)==0:\n",
    "                continue\n",
    "            # We'll take the time from the first row\n",
    "            time_myr = sub.iloc[0][\"time_Myr\"]\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(6,4), dpi=120)\n",
    "            ax.plot(sub[\"r_mid\"], sub[\"sigma_rad\"], 'r-o', label=r'$\\sigma_{\\mathrm{rad}}$')\n",
    "            ax.plot(sub[\"r_mid\"], sub[\"sigma_tan\"], 'g-o', label=r'$\\sigma_{\\mathrm{tan}}$')\n",
    "            ax.plot(sub[\"r_mid\"], sub[\"sigma_z\"],   'b-o', label=r'$\\sigma_{z}$')\n",
    "            ax.set_xlabel(\"r (kpc)\")\n",
    "            ax.set_ylabel(\"Velocity Dispersion (km/s)\")\n",
    "            ax.set_title(f\"M33 Kinematics, snap={snap}, t={time_myr:.1f} Myr\")\n",
    "            ax.legend()\n",
    "            plt.tight_layout()\n",
    "\n",
    "            outname = f\"M33_DiskKinematics_{snap}.png\"\n",
    "            #plt.savefig(outname)\n",
    "            plt.close(fig)\n",
    "            #plt.show()\n",
    "            print(f\"Saved {outname}\")\n",
    "\n",
    "    ########################################################################\n",
    "    # 3) Summarize final numeric results in a text or CSV\n",
    "    ########################################################################\n",
    "    massloss_file = \"M33_MassLoss.csv\"\n",
    "    summary_rows = []\n",
    "    # example: from massloss_file, we pick the final row\n",
    "    if os.path.exists(massloss_file):\n",
    "        df_loss = pd.read_csv(massloss_file)\n",
    "        last_row_loss = df_loss.iloc[-1]\n",
    "        summary_rows.append({\n",
    "            \"description\":\"Final M33 mass fraction\",\n",
    "            \"snapshot\": last_row_loss[\"snapshot\"],\n",
    "            \"time_Myr\": last_row_loss[\"time_Myr\"],\n",
    "            \"value\": last_row_loss[\"frac_bound\"]\n",
    "        })\n",
    "\n",
    "    # from diskfits_file, final row\n",
    "    if os.path.exists(diskfits_file):\n",
    "        df_fits = pd.read_csv(diskfits_file)\n",
    "        last_row_fit = df_fits.iloc[-1]\n",
    "        summary_rows.append({\n",
    "            \"description\":\"Final M33 sersic n\",\n",
    "            \"snapshot\": last_row_fit[\"snapshot\"],\n",
    "            \"time_Myr\": last_row_fit[\"time_Myr\"],\n",
    "            \"value\": last_row_fit[\"sersic_n\"]\n",
    "        })\n",
    "\n",
    "    if len(summary_rows)>0:\n",
    "        df_summary = pd.DataFrame(summary_rows)\n",
    "        df_summary.to_csv(\"Final_Summary.csv\", index=False)\n",
    "        print(\"Wrote a small summary table to Final_Summary.csv.\")\n",
    "    else:\n",
    "        print(\"No final summary to write (missing input files).\")\n",
    "\n",
    "    print(\"All final plotting/reporting steps completed.\")\n",
    "\n",
    "\n",
    "# Let's it\n",
    "# final_reporting()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5788a826-50d4-4bd1-8bb1-56743fc4d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16  ── warp & scale‑height analysis for M 33\n",
    "# (numpy, pandas, matplotlib already imported earlier)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Helper: rotate coordinates so the disk‑angular‑momentum vector is the z‑axis\n",
    "# -------------------------------------------------------------------------\n",
    "def RotateFrame(x, y, z, L):\n",
    "    \"\"\"\n",
    "    Rotate coordinates so the angular‑momentum vector **L** aligns with +z.\n",
    "    Returns x', y', z' arrays of same length.\n",
    "    \"\"\"\n",
    "    Lhat = L / np.linalg.norm(L)\n",
    "    zhat = np.array([0.0, 0.0, 1.0])\n",
    "    v    = np.cross(Lhat, zhat)\n",
    "    s    = np.linalg.norm(v)\n",
    "    c    = np.dot(Lhat, zhat)\n",
    "    if s == 0:                              # already aligned\n",
    "        return x, y, z\n",
    "\n",
    "    K  = np.array([[    0, -v[2],  v[1]],\n",
    "                   [ v[2],     0, -v[0]],\n",
    "                   [-v[1],  v[0],     0]])\n",
    "    R  = np.eye(3) + K + K @ K * ((1 - c) / s**2)\n",
    "\n",
    "    xyz_rot = R @ np.vstack((x, y, z))\n",
    "    return xyz_rot[0], xyz_rot[1], xyz_rot[2]\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Warp / scale‑height measurement helpers (unique to this cell)\n",
    "# -------------------------------------------------------------------------\n",
    "def compute_angular_momentum(x, y, z, vx, vy, vz, m):\n",
    "    \"\"\"Total angular‑momentum vector ∑ m (r × v).\"\"\"\n",
    "    Lx = np.sum(m * (y * vz - z * vy))\n",
    "    Ly = np.sum(m * (z * vx - x * vz))\n",
    "    Lz = np.sum(m * (x * vy - y * vx))\n",
    "    return np.array([Lx, Ly, Lz])\n",
    "\n",
    "\n",
    "def angle_between_vectors(a, b):\n",
    "    \"\"\"Return the angle (rad) between two 3‑D vectors.\"\"\"\n",
    "    cosang = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-30)\n",
    "    cosang = np.clip(cosang, -1.0, 1.0)\n",
    "    return np.arccos(cosang)\n",
    "\n",
    "\n",
    "def measure_warp_and_scaleheight(x, y, z, vx, vy, vz, m, nbins=10):\n",
    "    \"\"\"\n",
    "    In radial bins, compute the local tilt (warp) and vertical scale height.\n",
    "    Returns bin_mid, warp_angle[deg], scale_height[kpc].\n",
    "    \"\"\"\n",
    "    L_global = compute_angular_momentum(x, y, z, vx, vy, vz, m)\n",
    "    x_r, y_r, z_r = RotateFrame(x, y, z, L_global)\n",
    "    vx_r, vy_r, vz_r = RotateFrame(vx, vy, vz, L_global)\n",
    "\n",
    "    r     = np.hypot(x_r, y_r)\n",
    "    rmax  = r.max()\n",
    "    edges = np.linspace(0, rmax, nbins + 1)\n",
    "    mid   = 0.5 * (edges[:-1] + edges[1:])\n",
    "\n",
    "    warp_angle   = np.full(nbins, np.nan)\n",
    "    scale_height = np.full(nbins, np.nan)\n",
    "\n",
    "    for i, (rin, rout) in enumerate(zip(edges[:-1], edges[1:])):\n",
    "        idx = (r >= rin) & (r < rout)\n",
    "        if idx.sum() < 10:\n",
    "            continue\n",
    "\n",
    "        L_local = compute_angular_momentum(x_r[idx], y_r[idx], z_r[idx],\n",
    "                                           vx_r[idx], vy_r[idx], vz_r[idx],\n",
    "                                           m[idx])\n",
    "        warp_angle[i]   = np.degrees(angle_between_vectors(L_local, L_global))\n",
    "        scale_height[i] = np.std(z_r[idx])          # simple σ_z proxy\n",
    "\n",
    "    return mid, warp_angle, scale_height\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# MAIN: analyse morphology across snapshots\n",
    "# -------------------------------------------------------------------------\n",
    "def analyze_morphology_for_snapshots(snaprange=range(0, 802, 50),\n",
    "                                     datapath='M33/',\n",
    "                                     output_file='M33_morphology_results.txt'):\n",
    "    \"\"\"\n",
    "    Loop over snapshots, compute warp & scale‑height, write to *output_file*.\n",
    "    Relies on the *existing* CenterOfMass and Read() functions defined earlier.\n",
    "    \"\"\"\n",
    "    from pathlib import Path\n",
    "    out_path = Path(output_file)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(out_path, 'w') as f:\n",
    "        f.write(\"# snap  time[Myr]  R_bin[kpc]  warp[deg]  h_z[kpc]\\n\")\n",
    "\n",
    "        for snap in snaprange:\n",
    "            fname = Path(datapath) / f\"M33_{snap:03d}.txt\"\n",
    "            if not fname.exists():\n",
    "                continue\n",
    "\n",
    "            # reuse earlier CenterOfMass class (already imported)\n",
    "            com = CenterOfMass(np.loadtxt(fname, dtype=object), ptype=2)  # expects structured array\n",
    "            # However, our earlier COM class takes data, not filename.\n",
    "            # Instead, we can use the earlier Read() then CenterOfMass:\n",
    "            # time, _, data = Read(fname)\n",
    "            # com = CenterOfMass(data, ptype=2)\n",
    "\n",
    "            time = com.time\n",
    "            xcom, ycom, zcom = com.COMdefine()\n",
    "            vxcom, vycom, vzcom = com.COMdefinevel(xcom, ycom, zcom, radius=15.0)\n",
    "\n",
    "            # shift to COM frame\n",
    "            x  = com.x - xcom\n",
    "            y  = com.y - ycom\n",
    "            z  = com.z - zcom\n",
    "            vx = com.vx - vxcom\n",
    "            vy = com.vy - vycom\n",
    "            vz = com.vz - vzcom\n",
    "            m  = com.m\n",
    "\n",
    "            mid, warp, h_z = measure_warp_and_scaleheight(x, y, z, vx, vy, vz, m, nbins=10)\n",
    "\n",
    "            for R, w, h in zip(mid, warp, h_z):\n",
    "                f.write(f\"{snap:03d}  {time:9.2f}  {R:6.2f}  {w:6.2f}  {h:7.3f}\\n\")\n",
    "\n",
    "    print(f\"Done. Results saved to {out_path}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Example execution (commented out)\n",
    "# -------------------------------------------------------------------------\n",
    "# analyze_morphology_for_snapshots(snaprange=range(0, 802, 1),\n",
    "#                                  datapath='M33/',\n",
    "#                                  output_file='M33_morphology_results.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb2ffcc-55b4-4f65-b56e-050ce6f244d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17‑18  ── morphology‑results visualisation\n",
    "# (numpy, pandas, matplotlib already imported earlier)\n",
    "\n",
    "RESULTS_FILE = \"M33_morphology_results.txt\"   # change if stored elsewhere\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1.  Load the results table once\n",
    "# ------------------------------------------------------------------\n",
    "df = (pd.read_csv(RESULTS_FILE,\n",
    "                  comment=\"#\",\n",
    "                  delim_whitespace=True,\n",
    "                  names=[\"snapshot\", \"time_Myr\", \"R_kpc\",\n",
    "                         \"warp_deg\", \"scale_kpc\"])\n",
    "        .dropna(subset=[\"warp_deg\", \"scale_kpc\"]))           # drop incomplete bins\n",
    "\n",
    "unique_snaps = np.sort(df.snapshot.unique())\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  Warp angle vs radius for each snapshot\n",
    "# ------------------------------------------------------------------\n",
    "plt.figure()\n",
    "for snap in unique_snaps:\n",
    "    sub = df[df.snapshot == snap]\n",
    "    plt.plot(sub.R_kpc, sub.warp_deg, label=f\"snap {snap}\")\n",
    "plt.xlabel(\"Radius (kpc)\")\n",
    "plt.ylabel(\"Warp angle (deg)\")\n",
    "plt.title(\"M33 Disk Warp vs Radius\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"warp_vs_radius.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3.  Scale height vs radius for each snapshot\n",
    "# ------------------------------------------------------------------\n",
    "plt.figure()\n",
    "for snap in unique_snaps:\n",
    "    sub = df[df.snapshot == snap]\n",
    "    plt.plot(sub.R_kpc, sub.scale_kpc, label=f\"snap {snap}\")\n",
    "plt.xlabel(\"Radius (kpc)\")\n",
    "plt.ylabel(\"Scale height (kpc)\")\n",
    "plt.title(\"M33 Disk Scale Height vs Radius\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"scaleheight_vs_radius.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4.  Snapshot‑averaged trends (mean over the 10 radial bins)\n",
    "# ------------------------------------------------------------------\n",
    "snap_stats = (df.groupby(\"snapshot\")\n",
    "                .agg(time_Myr=(\"time_Myr\", \"first\"),\n",
    "                     warp_mean=(\"warp_deg\",  \"mean\"),\n",
    "                     scale_mean=(\"scale_kpc\", \"mean\"))\n",
    "                .reset_index())\n",
    "\n",
    "# 4a. Mean warp vs time\n",
    "plt.figure()\n",
    "plt.plot(snap_stats.time_Myr, snap_stats.warp_mean)\n",
    "plt.xlabel(\"Time (Myr)\")\n",
    "plt.ylabel(\"Mean warp angle (deg)\")\n",
    "plt.title(\"Disk Warp – Snapshot‑Averaged Trend\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"warp_vs_time_avg.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 4b. Mean scale height vs time\n",
    "plt.figure()\n",
    "plt.plot(snap_stats.time_Myr, snap_stats.scale_mean)\n",
    "plt.xlabel(\"Time (Myr)\")\n",
    "plt.ylabel(\"Mean scale height (kpc)\")\n",
    "plt.title(\"Scale Height – Snapshot‑Averaged Trend\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"scaleheight_vs_time_avg.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0492fb4f-cf42-4f79-81de-13dfb269d49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5875d19-f846-44e4-b86d-5b6a904e5266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8278b53d-da2d-4ca8-a847-6e73e0c25b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e68f0-6a2b-4303-a88e-4e20960e7842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b7c70c-63d1-4a88-896c-ad7326a897db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d925cb-714a-4fc7-8fd0-f7fd74e59c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73775049-b3a8-4664-b505-495ba44a58e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf97f2-355c-4eaa-877a-576d33fc1f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8baed7-0c8a-41a8-9b2c-a6ccee00ecb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb950db6-377b-4c47-b5c1-d7f19b4026d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125aa34b-9c34-4a98-aecb-aefe20eab34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47fa86c7-0cef-4d16-9687-7a90df2a19ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines of code in the notebook: 985\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "\n",
    "notebook_path = 'Project Code V5.ipynb'\n",
    "\n",
    "nb = nbformat.read(notebook_path, as_version=4)\n",
    "\n",
    "total_code_lines = 0\n",
    "\n",
    "for cell in nb.cells:\n",
    "    if cell.cell_type == 'code':\n",
    "        lines = cell.source.splitlines()\n",
    "        total_code_lines += len(lines)\n",
    "\n",
    "print(f\"Total lines of code in the notebook: {total_code_lines}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e4ef6-c57e-4de7-af2d-d397c184273d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
